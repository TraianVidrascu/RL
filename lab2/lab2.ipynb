{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of this assignment will be **automatically graded**. Please take note of the following:\n",
    "- Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "- You can add additional cells, but it is not recommended to (re)move cells. Cells required for autograding cannot be moved and cells containing tests cannot be edited.\n",
    "- You are allowed to use a service such as [Google Colaboratory](https://colab.research.google.com/) to work together. However, you **cannot** hand in the notebook that was hosted on Google Colaboratory, but you need to copy your answers into the original notebook and verify that it runs succesfully offline. This is because Google Colaboratory destroys the metadata required for grading.\n",
    "- Name your notebook **exactly** `{TA_name}_{student1_id}_{student2_id}_lab{i}.ipynb`, for example `wouter_12345_67890_lab1.ipynb` (or tim|elise|david|qi, depending on your TA), **otherwise your submission will be skipped by our regex and you will get 0 points** (but no penalty as we cannot parse your student ids ;)).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your names below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = \"Traian Vidrascu, Dragos Grama\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0fd6bc65a6759a8899e024459ccb28ef",
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer\n",
    "\n",
    "EPS = float(np.finfo(np.float32).eps)\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "039c8296578b2834a9a858a1a19a43bd",
     "grade": false,
     "grade_id": "cell-eecfd6fb626abfae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Temporal Difference (TD) learning (8 points)\n",
    "Mention one advantage and one disadvantage of Monte Carlo methods. Mention an example where you would prefer to use TD learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4b81bcd51404511164971c110ffa838f",
     "grade": true,
     "grade_id": "cell-cac4639044ba9074",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e61bd7837d3b364741b4c3aa43597a10",
     "grade": false,
     "grade_id": "cell-21ca38ffcbe1c3ca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For the TD algorithms, we will skip the prediction algorithm and go straight for the control setting where we optimize the policy that we are using. In other words: implement SARSA. To keep it dynamic, we will use the windy gridworld environment (Example 6.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "609d0f1e1ef6ad89c8dcd96dd43aa798",
     "grade": false,
     "grade_id": "cell-c046fd0377cee46d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from windy_gridworld import WindyGridworldEnv\n",
    "env = WindyGridworldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function and epsilon.\n",
    "    \"\"\"\n",
    "    def policy_fn(observation):\n",
    "        return int(np.random.rand() * nA) if np.random.rand() < epsilon else np.argmax(Q[observation])\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "?env.step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "42b89f13768d1cd3b41fb52cddef0d97",
     "grade": true,
     "grade_id": "cell-6b662771f3762bb1",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1059.62it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXwV9b3/8dcnhLDvBGRRAcGqta6ouLVWrFutcG/1VmsVLS1tH/ZXu3qtvbV21y5uV0tLxYpLXa8WaqmKiLuAQZFdCXuAkEA2sm/f3x/zPeGcZEJOQkIyh/fz8TiPM/Od78z5zpnkc77nM3Pma845REQktaR1dgNERKT9KbiLiKQgBXcRkRSk4C4ikoIU3EVEUpCCu4hIClJwl3ZjZv82s2ntvM3bzeyxNq672cwuaM/2JPm6Y8zMmVn6wX5tkRgFd0ngA2KFmZXGPe5PZl3n3CXOuTkd3caupiM/RMzsVjPb5I9Djpk9FVLnYTOrNbORjcpvN7Mav26Rmb1jZme21/ala1NwlzBfcM71jXt8u7MbdCjy34KuBS5wzvUFJgILG9XpA3wRKAauCdnMU37docAi4Jl23r50UQrukjQzu97M3jaz/zWzYjNbZ2aT45a/ZmZf89Pjzex1X293fI/QzM4ys/f8svfM7Ky4ZWP9envNbAFBUIpvwyTfAy0ysw/N7Lwk255mZreY2QYz22NmT5vZYL8slkaZZmZbfXt/ErduLzObY2aFZrbWzG42sxy/7FHgCOCfvvd7c9zLXtPM9k43sywzKzGzXWZ2VzPNPg14yTm3AcA5l+ucm9WozheBIuAXQLMpMedcLfA4MMrMMtt7+9IFOef00KPhAWwm6MmFLbseqAW+B3QHvkTQoxvsl78GfM1PPwH8hKAD0RM4x5cPBgoJeozpwNV+fohf/i5wF9AD+DSwF3jMLxsF7AEu9dv9nJ/PbGlfgO8Ci4HRftt/AZ7wy8YADvgr0As4EagCjvXL7wBeBwb59VcAOc29Z0ls713gWj/dF5jUTPu/AhQAPyLoVXcLqbMQ+B0w3B+bU+KW3R733mX4/dgNpLfH9vXo2o9Ob4AeXevhA1UpQW8t9vi6X3Y9sAOwuPpL4wJVfHB/BJgFjG60/WuBpY3K3vXbPsIHkD5xy/4eF6D+G3i00bovAdP2sy+x4L4WmBy3bARQQ/ABEwvGoxvt11V+eiNwUdyyryUZ3Jvb3hvAz4GhSRyPa4BXgDKCD7Jb4pYdAdQDJ8W9F/fGLb8dqPbHsM6vf157bV+Prv1QWkbCTHXODYx7/DVu2Xbn/9O9LUDYibabAQOWmtlqM/uqLx/p14m3haBXPhIodM6VNVoWcyRwpU/JFJlZEXAOQaBuyZHA83HrrSUIeMPj6uTGTZcT9Kpjbd4Wtyx+en+a29504GhgnU9LXdbcBpxzjzvnLgAGAt8EfmFmF/nF1wJrnXPL/fzjwJfNrHvcJp52zg0k2M9VwKntvH3pohTcpbVGmZnFzR9B0JtP4IL87dedcyOBbwB/MrPxvu6RjaofAWwHdgKD/Em8+GUx2wh67vEfPH2cc3ck0e5twCWN1u3pnNuexLo7CdIxMYc3Wt6qW6s659Y7564GhgF3As822uewdWqcc88QpISO98XXAePMLNfMcgnSWUOBS0LW301wHG43syYfhge6fel6FNyltYYB3zGz7mZ2JXAsML9xJTO70sxiAbGQIADW+bpHm9mXzSzdzL4EHAe84JzbAmQBPzezDDM7B/hC3GYfA75gZheZWTcz62lm58W9zv78Gfi1mR3p25dpZlOS3OengR+b2SAzGwU0vnpoFzAuyW1hZl8xs0znXD1BygSC96ZxvevN7PNm1s+fEL4E+CSwxF/SeBRwOnCSfxxPkMYKPfHpnFtHkFq5uSO2L12LgruEiV35EXs8H7dsCTCB4MTcr4ErnHN7QrZxGkGQKAXmATc55zb5upcBPyDI8d4MXOZ7lgBfBs4gONH3M4LcPQDOuW3AFOBWIJ+gN/4jkvs7vte342Uz20twcvWMJNaD4EqRHGATQX76WYITpDG/Bf7Hp3x+mMT2LgZW+/fmXoJcfGVIvRKCfd1K8CHwO+Bbzrm3CALsXOfcSv8tKdc5l+u3d1nsSqAQvwdmmNmwDtq+dBGWmD4VaZ6ZXU9wwvSczm5LZzKzbxEE5M90dltEmqOeu0gLzGyEmZ3tUxefIPjW8XxL64l0Jt37QqRlGQTXxY8lSF88CfypU1sk0gKlZUREUpDSMiIiKahLpGWGDh3qxowZ09nNEBGJlGXLlu12zmWGLesSwX3MmDFkZWV1djNERCLFzBr/2ruB0jIiIilIwV1EJAUpuIuIpCAFdxGRFKTgLiKSghTcRURSkIK7iEgKinRwf29zAXe9/BHVtfWd3RQRkS4l0sH9/S2F3PdqNrX1Cu4iIvEiHdxjdO8zEZFEkQ7uCSN5iohIg0gH9xh13EVEEkU6uBvquouIhEkquJvZ98xstZmtMrMn/KjzY81siZmtN7OnzCzD1+3h57P98jEduQMAGnBERCRRi8HdzEYB3wEmOueOB7oBVwF3Anc75yYAhcB0v8p0oNA5Nx6429frELGcu0K7iEiiZNMy6UAvM0sHegM7gfOBZ/3yOcBUPz3Fz+OXTzbTqU8RkYOpxeDunNsO/AHYShDUi4FlQJFzrtZXywFG+elRwDa/bq2vP6Txds1shpllmVlWfn7+Ae2EsjIiIomSScsMIuiNjwVGAn2AS0KqxkJsWC+9Sfh1zs1yzk10zk3MzAwdJapF+kIgIhIumbTMBcAm51y+c64GeA44Cxjo0zQAo4EdfjoHOBzALx8AFLRrqxtTz11EJEEywX0rMMnMevvc+WRgDbAIuMLXmQbM9dPz/Dx++auugy5nUb9dRCRcMjn3JQQnRt8HVvp1ZgH/DXzfzLIJcuqz/SqzgSG+/PvALR3Q7sQ2qusuIpIgveUq4Jz7GfCzRsUbgdND6lYCVx5401qmlLuISLhI/0I1RlfLiIgkinRwV8ddRCRcpIN7jDruIiKJIh3cY9e5694yIiKJIh7cO7sFIiJdU6SDe4z67SIiiSId3NVxFxEJF+ngHqOUu4hIomgHdyXdRURCRTu4e7r9gIhIokgHd/XbRUTCRTq4N1DHXUQkQaSDu1LuIiLhIh3cY9RxFxFJFOngbsRuP9DJDRER6WKSGUP1E2a2PO5RYmbfNbPBZrbAzNb750G+vpnZfWaWbWYrzOyUjmq80jIiIuGSGYnpI+fcSc65k4BTgXLgeYIRlhY65yYAC9k34tIlwAT/mAHM7IiGJ7RRiRkRkQStTctMBjY457YAU4A5vnwOMNVPTwEecYHFBANpj2iX1jaijruISLjWBvergCf89HDn3E4A/zzMl48CtsWtk+PLEpjZDDPLMrOs/Pz8VjYjkXLuIiKJkg7uZpYBXA4801LVkLIm4dc5N8s5N9E5NzEzMzPZZjRqU5tWExFJea3puV8CvO+c2+Xnd8XSLf45z5fnAIfHrTca2HGgDd0fddxFRBK1Jrhfzb6UDMA8YJqfngbMjSu/zl81MwkojqVv2psp6y4iEio9mUpm1hv4HPCNuOI7gKfNbDqwFbjSl88HLgWyCa6suaHdWtsMDbMnIpIoqeDunCsHhjQq20Nw9Uzjug64sV1a1xJ13EVEQkX6F6ox6riLiCSKdHBXx11EJFy0g7uuhRQRCRXp4B6jtIyISKJIB3f120VEwkU6uMfoxmEiIokiHdyVchcRCRfp4B6jnLuISKJIB3f13EVEwkU6uMeo4y4ikijSwV03DhMRCRfp4B6jG4eJiCSKdHCP5dwV2kVEEkU6uIuISLiUCO7KyoiIJEoquJvZQDN71szWmdlaMzvTzAab2QIzW++fB/m6Zmb3mVm2ma0ws1M6qvG6cZiISLhke+73Ai86544BTgTWArcAC51zE4CFfh6CsVYn+McMYGa7tjiUuu4iIvFaDO5m1h/4NDAbwDlX7ZwrAqYAc3y1OcBUPz0FeMQFFgMDYwNptzf120VEwiXTcx8H5AN/M7MPzOxBM+sDDI8NfO2fh/n6o4Btcevn+LIEZjbDzLLMLCs/P/+AdkI5dxGRRMkE93TgFGCmc+5koIx9KZgwYR3qJuHXOTfLOTfROTcxMzMzqcY2eSF13UVEQiUT3HOAHOfcEj//LEGw3xVLt/jnvLj6h8etPxrY0T7NDaeOu4hIohaDu3MuF9hmZp/wRZOBNcA8YJovmwbM9dPzgOv8VTOTgOJY+qa96fYDIiLh0pOs9/+Ax80sA9gI3EDwwfC0mU0HtgJX+rrzgUuBbKDc1+1QyrmLiCRKKrg755YDE0MWTQ6p64AbD7BdSVHOXUQkXGr8QlVZdxGRBJEO7rGOu9IyIiKJoh3clZYREQkV6eAeo567iEiiiAd3dd1FRMJEPLgHdEJVRCRRpIO7cu4iIuEiHdxjlHMXEUkU6eCujruISLhIB3cREQkX6eCuYfZERMJFOrjHKOcuIpIo0sG94fYDuhRSRCRBtIO7sjIiIqEiHdxjlJYREUmUVHA3s81mttLMlptZli8bbGYLzGy9fx7ky83M7jOzbDNbYWandFTj1XMXEQnXmp77Z51zJznnYoN23AIsdM5NABayb9DsS4AJ/jEDmNlejW2OOu4iIokOJC0zBZjjp+cAU+PKH3GBxcDA2EDa7U1jqIqIhEs2uDvgZTNbZmYzfNnw2MDX/nmYLx8FbItbN8eXJTCzGWaWZWZZ+fn5bWt9rHFKuouIJEh2gOyznXM7zGwYsMDM1u2nblh3ukn0dc7NAmYBTJw4sW3RWR13EZFQSfXcnXM7/HMe8DxwOrArlm7xz3m+eg5weNzqo4Ed7dXg0PZ15MZFRCKoxeBuZn3MrF9sGrgQWAXMA6b5atOAuX56HnCdv2pmElAcS9+0N3XcRUTCJZOWGQ487+/jkg783Tn3opm9BzxtZtOBrcCVvv584FIgGygHbmj3VjeilLuISKIWg7tzbiNwYkj5HmBySLkDbmyX1rVg343DFN1FROJF+heqSsuIiISLdHCPUVpGRCRRpIO7bj8gIhIu0sE9Rh13EZFEkQ7uuv2AiEi4SAf3GOXcRUQSRTq4K+cuIhIu0sE9RjcOExFJFOngro67iEi4SAf3GPXbRUQSRTu4+667sjIiIokiHdx1KaSISLhIB/cYp8SMiEiCSAd3XQopIhIu0sG9gTruIiIJkg7uZtbNzD4wsxf8/FgzW2Jm683sKTPL8OU9/Hy2Xz6mY5quSyFFRJrTmp77TcDauPk7gbudcxOAQmC6L58OFDrnxgN3+3odSh13EZFESQV3MxsNfB540M8bcD7wrK8yB5jqp6f4efzyyWYdkx3voM2KiEResj33e4CbgXo/PwQocs7V+vkcYJSfHgVsA/DLi339DqPr3EVEErUY3M3sMiDPObcsvjikqktiWfx2Z5hZlpll5efnJ9XYptto02oiIikvmZ772cDlZrYZeJIgHXMPMNDMYgNsjwZ2+Okc4HAAv3wAUNB4o865Wc65ic65iZmZmQe0E7rOXUQkUYvB3Tn3Y+fcaOfcGOAq4FXn3DXAIuAKX20aMNdPz/Pz+OWvug66bWOs4660jIhIogO5zv2/ge+bWTZBTn22L58NDPHl3wduObAmNk9pGRGRcOktV9nHOfca8Jqf3gicHlKnEriyHdqWfLsO5ouJiERAxH+hqq67iEiYiAf3gEZiEhFJFOngrpy7iEi4SAf3GPXbRUQSRTq4q+MuIhIu0sG9gbruIiIJIh3cdeMwEZFwkQ7uMbr9gIhIokgHd/XbRUTCRTq4x+gydxGRRJEO7rGUu4K7iEiiaAd3JWZEREJFOrjHqOMuIpIo0sFdV0KKiISLdHCP0Y3DREQSpURwFxGRRMkMkN3TzJaa2YdmttrMfu7Lx5rZEjNbb2ZPmVmGL+/h57P98jEduwvKuYuINJZMz70KON85dyJwEnCxmU0C7gTuds5NAAqB6b7+dKDQOTceuNvX6xD7LoVUeBcRiZfMANnOOVfqZ7v7hwPOB5715XOAqX56ip/HL59sHXwTmG8+9n5Hbl5EJHKSyrmbWTczWw7kAQuADUCRc67WV8kBRvnpUcA2AL+8mGAA7cbbnGFmWWaWlZ+f36bG6zp3EZFwSQV351ydc+4kYDTBoNjHhlXzz2ERt0nexDk3yzk30Tk3MTMzM9n2iohIElp1tYxzrgh4DZgEDDSzdL9oNLDDT+cAhwP45QOAgvZobGO6zl1EJFwyV8tkmtlAP90LuABYCywCrvDVpgFz/fQ8P49f/qrroDOeCu4iIuHSW67CCGCOmXUj+DB42jn3gpmtAZ40s18BHwCzff3ZwKNmlk3QY7+qA9otIiL70WJwd86tAE4OKd9IkH9vXF4JXNkurWuBTqiKiITTL1RFRFJQpIN7bX19ZzdBRKRLinZwr9MvU0VEwkQ7uKvnLiISKtLBvUY9dxGRUJEO7krLiIiEi3Rwr1FaRkQkVKSDu4iIhIt0cP/0hOCGY+OH9e3kloiIdC3J3H6gy+qWZpw5bgh19cq9i4jEi3TPHSAtDeo1EpOISILIB3fDFNxFRBqJfnA3DZAtItJY5IN7mhlKuYuIJEqB4A4dNBaIiEhkJTMS0+FmtsjM1prZajO7yZcPNrMFZrbePw/y5WZm95lZtpmtMLNTOnIHzJRzFxFpLJmeey3wA+fcsQRjp95oZscBtwALnXMTgIV+HuASYIJ/zABmtnur4wQ99458BRGR6GkxuDvndjrn3vfTewnGTx0FTAHm+GpzgKl+egrwiAssJhhIe0S7t9wz5dxFRJpoVc7dzMYQDLm3BBjunNsJwQcAMMxXGwVsi1stx5c13tYMM8sys6z8/PzWt9xTzl1EpKmkg7uZ9QX+D/iuc65kf1VDyppEX+fcLOfcROfcxMzMzGSbEfJiyrmLiDSWVHA3s+4Egf1x59xzvnhXLN3in/N8eQ5weNzqo4Ed7dPcptLSlHMXEWksmatlDJgNrHXO3RW3aB4wzU9PA+bGlV/nr5qZBBTH0jcdQVfLiIg0lcyNw84GrgVWmtlyX3YrcAfwtJlNB7YCV/pl84FLgWygHLihXVvcSJqZeu4iIo20GNydc28RnkcHmBxS3wE3HmC7kmYkd+Ow+nqHWdDTFxFJdanxC9UW6hSUVTPu1vk8/M7mg9EkEZFOF/ngXlPn2LKnnIrqOorKq1m2paBJnZ3FFQA89d62JstERFJRpAfrAPjXyuBc7V/f3Mgra3exIqeYjb+5lLS0femX9LTgM0wnXkXkUBH5nntMbb1j5fZiAOoaBfFuafvqiIgcClImuOeVVDZcNdN42L00fxK1XsFdRA4RKRPcn4zLpzeXflHPXUQOFSkT3OM17rnHZtVzF5FDxSES3IN59dxF5FBxSAX32PODb24kp7D8oLdLRORgSc3g3ijnHgv2tfWOvJJKfvWvtVz/t/c6o2kiIgdFSgb3+vrE+firaGKBv7Sy9iC3SkTk4EnJ4F4bF92dc2wrCFIwdfVONxkTkUNCSgb3DfllDdNPLN3Gtx5/H/DB3Zfr/mEikspSMrhPe2gpb64Phu679fmVDeVBzz0I74rtIpLKIh/cPzVqQGj5hrzSJmV1bl9aRrf+FZFUlsxITA+ZWZ6ZrYorG2xmC8xsvX8e5MvNzO4zs2wzW2Fmp3Rk4wH+cu2poeXdujXdNeeaXus+87UN/OqFNR3SNhGRzpJMz/1h4OJGZbcAC51zE4CFfh7gEmCCf8wAZrZPM5vXIz18F9LTwnvmsZuLxdz54joefGtTu7dLRKQztRjcnXNvAI1vkj4FmOOn5wBT48ofcYHFwMDYINodpVszQbxbM2mX7zzxAaATqiKS2tqacx8eG/TaPw/z5aOA+BExcnxZE2Y2w8yyzCwrPz+/jc0g4b7t8Rr/kKnp67f5JUVEurz2PqEaFjJDo6xzbpZzbqJzbmJmZmabX7C5HnpVTV3DlTFhTNfLiEgKa2tw3xVLt/jnPF+eAxweV280sKPtzWtZWjPBvbK2ntySyo58aRGRLqutwX0eMM1PTwPmxpVf56+amQQUx9I3HSWtmT14aXUuZ/721WbXU1pGRFJZi2OomtkTwHnAUDPLAX4G3AE8bWbTga3Alb76fOBSIBsoB27ogDYnaC4t88HWov2up9guIqmsxeDunLu6mUWTQ+o64MYDbVRrNHe1jIjIoSzyv1Bt6y9N9QtVEUllkQ/ubRUW2h96axOrGv3ISUQkilpMy6SskOj+C38bgs13fP4gN0ZEpH2lbM+9pazLxvwyTv7Fyw3zqTp49hsf57O9qKKzm3HIe+TdzbyyZldnN0MOISkb3DNCbhzWWGF5TcN0VW39fmpG13UPLeXie97o7GZ0GdsKyqmsqTvor3vb3NV87ZGsg/66cuhK2eDePYngHq+sOnHYveLymoYRnPZn0Ud5rN7RNfP0sV/o7j3EhxR85N3NPPLuZurqHef+bhHf/vsHB7S9nMJyvvFoFhXVB/9DQiRZKRHc/3b9aU3KWnstTHlV4j/q5//3Tc793aKG+bC0zfl/eI0b/vYen7/vrdBtVtfWM/O1DVTVdk4QqKlLzVRTa902dzW3zV3N3Qs+BuCVtQeWHvnN/LW8tHoXiz4KfpjtnNvvrS5SxX0L1/Pw27qDalSkRHD/7DHDuOWSYxLKWnulY+Oee07hvjz1e5sLGHfrfN7fWphQZ+PuMvbniaVbufPFdcxux1sKv7hqJ1/fz9f7dbkl7C6tAui0D5Wu6v5F2QnzReXV3P/qeupaeb4ldl+ieh/Q/3PmOxx320vN1m/t9ruquxZ8zO3/7JyxD7YXVbC5hf83SZQSwR2a/lK1tdexr48buSk+zbK7tIo/vPQRAG9+vJvKmjqqa+up3k+OvrSqlrp6R4XP7RbH5faT4Zxj0bo8rpj5Di+vzk1Y9s3H3mfBml3U1iW+/tJNBeytrOHie97kMv9N4tHFW1r1uskoqaxJ6KWWVdV26V7r/k4m//pfa/nDyx/zxsetvCup/9OK7fYHW4sajnWY8urwtNj2ogo+yt1LQVk1HzTqOEiis+94lfP+8FpnN6PV9la27n+/PaXMpZCNb/0b9sPVb3x6HH95Y2Po+rH7vAO8ujavYfr6vy1l1fYSAByOY376Iscc1q/Z4f2ccxz/s5cYOaAnO4qDG5ftLz1SX++448V1XHPGEYwc2Iv/+NPbHJXZl7nLg/utZT26jDdv/izbiyoYl9mnYb3SqloG9s4AgoD7X395t2FZ7IZpv3vxo2ZftyXLthQwelBvhvfv2VCWnVfKBXe9zh+vPJEvnjqabQXlnPu7RXzrvKP474uDb061dfUsXJfHhccN7xI/FDv7jvD7C1XH3ViuJO4fcF1uCelpaYwf1heAPaVVrM8rZdK4IQ11YntVVtXyuYyN+aUJA7aHtW38sL5k55Wy6beXdon3rCsrqayhR3oaPdK7tWn99bv28sraPG44eww9u7dtG5U1dbyzYTfnHzN8v/XmLt/OTU8u58Xvnssxh/Vv02sdiBTque+bvvzEkaF3ixwxoGeTsjB/9LlZoCGwA9zzynoA1uXu5ZllOQnrVFTX8T//WMmKnKDXHwvsAA+9vYmPd+1NqJ+1uYCVOcWs2F7MrDc28pnfv8aEn/ybVdtLGgJ7zLm/W8RVsxYz7aH3Gso27S7jly+sYdG6vA75uvrFme9y6b1vJpQt3rgHgHkf7uDW51eybEvQ25z52gaWbQnGc3lg0Qa+8egyFn2UR2FZdatOOubvrWryjehrc97j9nmrG+YLy6r3G1SrauuY9+GOFr9NTH3gbd5cvxuAm55c3pDCuvieN7ngrtcb6l07eylXzVpMTdw3pVgAvuW5lbTk/D++vt80GgQfmkHbD94VW5U1dRSUVbdYb1tBOZ+87cU2/7ivorqOE3/+MgvW7OKd7N3sLK5g+bYisvP2trxyiBNuf5lr/rqkTesCfO7uN7jzxXX86l9tTy/9/J9r+OrDWS1eSLHQdxLX7CjZb72OkjLBPfavPP2csdx39cmhN5Ev78BL4I697UUeW7yVKQ+8Hbr8wrvfSLjO+Yo/v8sX7n+Lqc3UD7N2574/kv/40zvMfmsTNzz8Hpff3/I2WnP5XyzQ7Smrpr7e8XTWtoRg8PrH+fx9yVa++9TyhnWmzwkC2MbdQaAqKKvh5F8uSPhGEfPB1sImwaKmrp7Tfv0Kt/zfioTyV9bm8fA7m7ngrteprq3n5F8u4PL732JDfin/84+VTfLZD7yazXee+IAXVuzkB09/2Ow+rtmZ+A+3o6iSn/9z34fIL/0P2mL19pTuC4Rb9+z7MH1x1b6bnjb+QGkuHdOcl1bnUlVbR05hOa+s2cX2ogq27Cnj3lfWN5s62rS7jDfXN59Wqqt3/PQfq5p0Lq6bvZRTfrmgSf3Sqlp++MyH5PlvNS+tzqWsuo47/r2uoU5FdR3rcku4be6qhvc/b29lwnsRs7WgnOKKGm78+/t8+cElXH7/20x94G0uuOsNXv84nwk/mU+h/7vK31vFc+/nNNlGY1lbkkthXXj369zzStBRq6ypa/gQBVi/q7RJ/WeX5fDk0q0tbvej3OBvojTJq9DCOpp5JZVc9r9v8nb27qS20RYpk5a5cuLhrMwp5qrTgtvJ9++ZntAzueyEEc32Ii85/jAqaurI7NujSY98f6aeNJJ/LE/+dvVfeySL70yewH0L1ye9TluNueVfCfPH/PRFNv7mUhZv2sO4oX05bEBPCsuq2bi7jFOPHJRQN/4cwZQH3mbl9mLW7ixhZ1Hz98cvKq9h2kNL6dsz+JOK5aBXbi8mt7iS38xfyw8uPJojBvfmP/70DgCbfnspVbX13PrcSs4ePxSA5z7Yzi+mHs/yrUUcM6Jfw/az80r5zfy1AGzIL2PyH4Pe9adGDeBLpx3B0k0FpBls922849/rWvXjrc82yufOfmsT3/zMUQ3zd/x7LWlpxnPvb0+o983H3m+Y/uncVZx91FAu+VQwsmT8SfmYma9tYOKYQQzq3b3JspueXM7Vpx/OE0u3NVkGcNPkCZwxbk83nUgAAAwfSURBVDBnjhvS8O3h/D++RvxnytWnH8Htlx/H4o0FHNa/J2bBuZdHF2/hvqtP5vITR7JmRwlLNwfftH79rzX89c3ghP+9V53EhrxSnl2Ww9aCcmZPm0iGH6P4rbggtOijPO5buJ51uXu55owj+cRh/fj6nCw+zClm+W2fI29vFUcO6U2P9G5s9ZcTx76R5e+tatjOtIeWArA8p4izjhrCab9+BYDTxgzmz69v4PMnjOCso4bu91tYUXk1v52/jqMP68f4YX156r2tfGXSkZwweiAf7yrl413r6ZORzpJNBQlXSS3ZVIBzjqraehZv3ENReQ0/fCboDPTK6EZeSRXXTDqC3OJK1uXu5dJPjWBdbgnjM/sSy7J+adZivv3Z8Rw+uBfFFTWUVtZy7Ij+Dcc/1urYifcfP7eCAb0yOGf8UL4yO/j2cc2DSzrsF/HWFU6GTZw40WVlte8PPNbsKOHprG189eyx9OiexqDeGWzcXcrF97zJvVedxOodJfRMT+PMo4Zy5lH78qnjb51Pre+NDOrdPeGHTk1e4xcX8fLqXTy6eEtDiqKj3HrpMfxm/rqWKybphrPH8Le3NwNw0SeH0y3N+PElx7KjqIIvzVqc9HaOGNybC48bvt9Bxi8/cSTzPuzQMVva7JQjBvJ+C7eHbq2vnzuWcyZksmxLYYd8kE8/Zyy5xZXk761qCNLJOuawfqzLTT4lcvyo/gmpyTDHjuif8K0yZlxmHzY2c77hQH3+hBHkFld2+P9dW7z+o/NYtC6P5z/Yzoc5xdxw9hgG985ISPfG2/ibS5sdLrQlZrbMOTcxdFmqBve2eml1Lne+uI4nvz6JAb27U1Vbz9+XbOW4Ef0prqhhfV5pwz9s7BO3qLyak34RfMX95meO4s+vb+AfN57NjY+/z/aiCs46agjvbNjT5LV+f8UJLFizi5fj0jWD+2TwwJdPYVtBOVNPHsWr6/I4Z8JQ+vZIZ1tBOf17dueFlTv4yfOrAPj3TedSXFHDVbMW89SMSYwc2Iv/98QH9M7oxuA+GQzv37PNl2Ie1r9ns6NZXXbCCF5YsZMLjh3OV88Zw5cPIA/aUYb0yWBPWTWZ/Xow85pTeGzxFnplpPOFE0cwuE8GA3p1Z1i/nhx16/xWb/tnXziOZ5flsHpHCedOGNqQvw9z13+dyPq8Uma+tuFAdqdLmDCsb8KVZW11VGafZk80hzluRP8mqbRk/OfJo3jug+10SzN6de9GaVVtu+1De/nRRZ/gxs+Ob9O6Bz24m9nFwL1AN+BB59wd+6vflYJ7Mqpr66mqraNfz31frbcVlPPMshy+d8EEisprGNQng+KKGmrr6umV0Y2XV+9i9Y5ithdV8IcrT6Sypr7hq3lBWTUVNXX07N6N9DRruAqmOYVl1dy/KJtpZ47hiCG991vXOcf9r2YzLrMvSzbt4cghfXhgUTYFZdX07ZHOsSP6MbB3BjM+PY67F3xMTV09q7aX8Kupx/PFU0ezekcxeSVVLN64hx7paRw2oBd5eyu5afIEXlmbx6Rxg+nXs3vDD3rySio5Z0ImSzftoaqmnn+u2MFRmX3JK6mitt6xp6yKD7cVcf4xw5h21hjySqr4YFshg3pn8P3PHU1ReQ3bCsspqaglO28vRx/Wj6LyGhZv3MMRg3szamAvMtLTOPXIQdy3MJsLjhtGcXkNp44ZxFNLt3HcyP5MPnb/VzE0tmp7MX17pDOwd3f69ezOgjW7WLalgIz0NM6dkElNXT27S6sYM6QP/Xp2p7iimlOPHExVbR1vfrybzx4zjJzCcnpnpPPAomy2FZRTVl1Lr+7dOGPcEL75maOoq3eUVtaSkZ5G3t5KRg/qzZodJeQUlrNgzS6W5xQx69qJZOeVUlRezbrcvWwtKOeIwb2ZNG4wnxw5gN4Z3di4u4y1O0vYW1nLsH49qKipI6+kik8fncmoQb2orKlj/oqdXHvmkeQUVlBSWcP4zL68v7WIM8YOpqiihnU7Szh97GAqauro3i2NNDM+yt3Liu1FOBekRYb168GWgnI25Zdy5lFD2bS7jDPGDqa8po43P87njHFDyC2uZFj/HvTv2Z26ekeaTwFdd+YY8vZW8v6WQnqkd+O4kf05YkhvistrOHxw4t9rfb1jb2UtfXp0I7ekkv69utMjPY3iihr69+xOuU+lDu6TwYfbivgody9pacaRQ3qzflcp44f15ZgR/bj/1WwuP3Ekg/tk0Ccjneq6etIMhvTt0fBalTV11NTVN/zfvpO9m3sWrudHF32Co4f1C9IxeyvJSE8js28PNuSXsX5X8Ho/fPpDxmb24VOjBlBRU0ducSU/vew4yqpqeSYrh57d00jvlkZhWTUrthczoFd3xg7tw5ghvdmQX0ZReTVnjBvCpydk8sKKHVTU1LF0UwHD+/fk91eckNDO1jiowd3MugEfA58jGFP1PeBq51yzp6ejFtxFRLqC/QX3jrha5nQg2zm30TlXDTwJTOmA1xERkWZ0RHAfBcSf7s/xZSIicpB0RHAPO+3bJPdjZjPMLMvMsvLzW/nzbxER2a+OCO45wOFx86OBJtfBOedmOecmOucmZmZmdkAzREQOXR0R3N8DJpjZWDPLAK4C5nXA64iISDPa/ReqzrlaM/s28BLBpZAPOedWt7CaiIi0ow65/YBzbj7Q+l+GiIhIu0iZG4eJiMg+XeL2A2aWD7R1ZImhQMfdWq1r0j4fGrTPh4YD2ecjnXOhV6R0ieB+IMwsq7lfaKUq7fOhQft8aOiofVZaRkQkBSm4i4ikoFQI7rM6uwGdQPt8aNA+Hxo6ZJ8jn3MXEZGmUqHnLiIijSi4i4ikoEgHdzO72Mw+MrNsM7uls9vTXszscDNbZGZrzWy1md3kyweb2QIzW++fB/lyM7P7/PuwwsxO6dw9aBsz62ZmH5jZC35+rJkt8fv7lL9XEWbWw89n++VjOrPdbWVmA83sWTNb54/1mYfAMf6e/5teZWZPmFnPVDzOZvaQmeWZ2aq4slYfWzOb5uuvN7NprWlDZIO7H/HpAeAS4DjgajM7rnNb1W5qgR84544FJgE3+n27BVjonJsALPTzELwHE/xjBjDz4De5XdwErI2bvxO42+9vITDdl08HCp1z44G7fb0ouhd40Tl3DHAiwb6n7DE2s1HAd4CJzrnjCe49dRWpeZwfBi5uVNaqY2tmg4GfAWcQDIL0s9gHQlKcc5F8AGcCL8XN/xj4cWe3q4P2dS7BsIUfASN82QjgIz/9F4KhDGP1G+pF5UFwa+iFwPnACwTjAuwG0hsfb4Kb0p3pp9N9PevsfWjl/vYHNjVud4of49hAPoP9cXsBuChVjzMwBljV1mMLXA38Ja48oV5Lj8j23DlERnzyX0VPBpYAw51zOwH88zBfLRXei3uAm4F6Pz8EKHLO1fr5+H1q2F+/vNjXj5JxQD7wN5+KetDM+pDCx9g5tx34A7AV2Elw3JaR2sc5XmuP7QEd8ygH96RGfIoyM+sL/B/wXedcyf6qhpRF5r0ws8uAPOfcsvjikKouiWVRkQ6cAsx0zp0MlLHva3qYyO+zTylMAcYCI4E+BCmJxlLpOCejuf08oP2PcnBPasSnqDKz7gSB/XHn3HO+eJeZjfDLRwB5vjzq78XZwOVmtplgQPXzCXryA80sdlvq+H1q2F+/fABQcDAb3A5ygBzn3BI//yxBsE/VYwxwAbDJOZfvnKsBngPOIrWPc7zWHtsDOuZRDu4pO+KTmRkwG1jrnLsrbtE8IHbGfBpBLj5Wfp0/6z4JKI59/YsC59yPnXOjnXNjCI7jq865a4BFwBW+WuP9jb0PV/j6kerROedygW1m9glfNBlYQ4oeY28rMMnMevu/8dg+p+xxbqS1x/Yl4EIzG+S/9Vzoy5LT2ScdDvCExaXAx8AG4Ced3Z523K9zCL5+rQCW+8elBPnGhcB6/zzY1zeCK4c2ACsJrkbo9P1o476fB7zgp8cBS4Fs4Bmghy/v6eez/fJxnd3uNu7rSUCWP87/AAal+jEGfg6sA1YBjwI9UvE4A08QnFeoIeiBT2/LsQW+6vc/G7ihNW3Q7QdERFJQlNMyIiLSDAV3EZEUpOAuIpKCFNxFRFKQgruISApScBcRSUEK7iIiKej/A++qEJVsJtnKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sarsa(env, num_episodes, discount_factor=1.0, alpha=0.5, epsilon=0.1, Q=None):\n",
    "    \"\"\"\n",
    "    SARSA algorithm: On-policy TD control. Finds the optimal epsilon-greedy policy.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        epsilon: Probability to sample a random action. Float between 0 and 1.\n",
    "        Q: hot-start the algorithm with a Q value function (optional)\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is the optimal action-value function, a dictionary mapping state -> action values.\n",
    "        stats is a list of tuples giving the episode lengths and rewards.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The final action-value function.\n",
    "    # A nested dictionary that maps state -> (action -> action-value).\n",
    "    if Q is None:\n",
    "        Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    # Keeps track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "    # The policy we're following\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)\n",
    "    \n",
    "\n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        s = env.reset()\n",
    "        a = policy(s)\n",
    "        end = False\n",
    "        \n",
    "        while not end:\n",
    "            \n",
    "            s_new,r,end,prob = env.step(a)\n",
    "            a_new = policy(s_new)\n",
    "            Q[s][a] = Q[s][a] + alpha * (r + discount_factor*Q[s_new][a_new] - Q[s][a])\n",
    "            s = s_new\n",
    "            a = a_new\n",
    "            i += 1\n",
    "            R += r\n",
    "        \n",
    "        stats.append((i, R))\n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)\n",
    "\n",
    "Q_sarsa, (episode_lengths_sarsa, episode_returns_sarsa) = sarsa(env, 1000)\n",
    "\n",
    "# We will help you with plotting this time\n",
    "plt.plot(episode_lengths_sarsa)\n",
    "plt.title('Episode lengths SARSA')\n",
    "plt.show()\n",
    "plt.plot(episode_returns_sarsa)\n",
    "plt.title('Episode returns SARSA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1e8df3908ce548708b64f69e11a34896",
     "grade": false,
     "grade_id": "cell-0eaf4b925ab3ea34",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We learn the optimal (non-exploring) policy while using another policy to do exploration, which is where we arrive at _off-policy_ learning. In the simplest variant, we learn our own value by bootstrapping based on the action value corresponding to the best action we could take, while the exploration policy actual follows the $\\epsilon$-greedy strategy. This is known as Q-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "954556134388a34f8d4b9a07834180c5",
     "grade": true,
     "grade_id": "cell-a87637d2e582fec0",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1480.65it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxeZZ338c8v+9akaZKuaZuuLC0FSigti4NQKDuoMII6lEVxFERn9FGQR9l5RsdRQJERZ8BBGRAFEVksVFRUli4IhbI13Uu3tE3XNG2W3/PHOUnvNUmblLTn/r5fr7x639dZ7uuck37Pletc9znm7oiISGbJ6usKiIjIh0/hLyKSgRT+IiIZSOEvIpKBFP4iIhlI4S8ikoEU/tIjZvasmc3s5XXeZGa/6M11Rllf7i8z+08z+1ZffLb0jMJfMLNlZrbTzLbH/PyoO8u6+5nu/j/7u477y4F2ojGz/mZ2r5mtNbNGM3uzt0+uvcnd/9ndb+3resjey+nrCsgB41x3n93XlehNZpbj7i0Hy2eYWR4wG1gPTANWAacC/2NmZe5+d298zl7UZ7/vP+k7avlLp8zsMjP7m5n90My2mNm7ZnZqzPQ/mdlnw9djzezP4XwbzOyXMfMdb2Zzw2lzzez4mGmjwuW2mdnzQGVCHaaa2UtmttnM3jCzkzup7zIz+4aZLQB2mFmOmQ01s8fMrN7MlprZteG8ZwDfBD4Z/rXzRsw6psess+OvAzOrMTM3syvNbAXwQkzZTDNbEW77DTHLTzGzeWa21czWmdn301T/n4ARwEXuvtTdm93998C1wG1m1q/Tg9WN/WVml5vZO+G+XmJmn4+ZdrKZrQr331rggZiyr5rZejNbY2aXxyzzMzO7LWH5dPNWmNnvwv0w18xuM7O/dmebpPcp/KU7jgOWEITyjcDjZjYgxXy3As8B5UA18EOAcN6ngbuBCuD7wNNmVhEu97/A/HD9twId3RxmNixc9jZgAPA14DEzq+qkvpcAZwP9gTbgd8AbwDCClvRXzGxGGKx3AL909xJ3P3Iv9sk/AIcBM2LKTgQOCT/j22Z2WFh+F3CXu5cCY4BH06zzNOBZd9+RUP4YUARM7apS3dhf64FzgFLgcuAHZjY5ZhWDw+VGAlfFlJUR7L8rgXvMrDxNFTqb9x5gRzjPTGKOs3z4FP7S7omwpdj+87mYaeuBO8OW6C+B9wjCNVEzQWgMdfcmd29v1Z0NLHL3n7t7i7s/DLwLnGtmI4BjgW+5+y53f5EgrNt9BnjG3Z9x9zZ3fx6YB5zVybbc7e4r3X1nuO4qd7/F3Xe7+xLgp8DFe7l/Et3k7jvCz2h3s7vvdPc3CE427SeTZmCsmVW6+3Z3fyXNOiuBNYmFYdfLBqCzE167TveXuz/t7os98GeCk/VJMcu3ATeGx6J925qBW8Lj/wywneAkl0rKec0sG/hEuO5Gd38bOGivFUWBwl/aXeDu/WN+fhoz7QOPvwPgcmBoinV8HTBgjpktNLMrwvKh4TKxlhO0DocCDQmt3dh5RwIXxZ6YCFrYQzrZlpUJyw9NWP6bwKBOlu+OlSnK1sa8bgRKwtdXAuOBd8PujnPSrHMDKbbLzHIITgz1ZvZp23NR/tkU6+h0f5nZmWb2ipltCqedRXw3W727NyWsc2NC33/stiVKN28VwTXG2P2Wah/Kh0QXfKU7hpmZxZwARgBPJs7k7muBzwGY2YnAbDN7EVhNEEqxRgC/J2jplptZccwJYATQ/lkrgZ+7++fovtgT1UpgqbuP68a87XYQdLO0G9zN5VJ/gPsi4BIzywI+DvzazCpSdO/MBu5I2BcQtJibgTnuvgV4qJOPS7u/zCyfoAvpUuC37t5sZk8QnLD3erv2Uj3QQtAd+H5YNnw/fZZ0g1r+0h0DgWvNLNfMLiLo634mcSYzu8jMqsO3DQRB0hrOO97MPhVegP0kcDjwlLsvJ+iWuNnM8sKTxrkxq/0FQffQDDPLNrOC8MJiNd0zB9gaXsQsDNcx0cyODaevA2rCYG73OnBxuL21wIXd/KyUzOwzZlbl7m3A5rC4NcWsPycY4fOr8CJyrpnNILhW8t0w+LvS2f7KA/IJg9jMzgRO78m2dZe7twKPAzeZWZGZHUpwEpI+ovCXdr+z+HH+v4mZ9iowjqBb4nbgQnffmGIdxwKvmtl2gr8MvhyOWtlIcJHxq8BGgu6hc9x9Q7jcpwguKm8iuKD8YPsK3X0lcD5BV009Qcv2/9DN390wdM4FjgKWhtvwXwQXJQF+Ff670cxeC19/i+DCbANwM8EF6Z44A1gY7pe7gItTdK3g7ruA6QTb+Cqwk+CvozvDenSps/3l7tsIRg49SrBtnyLFX3D70TUE+30twYnuYWDXh/j5EsP0MBfpjJldBnzW3U/s67pkGjPLBZ4FPgAu84j9ZzWz7wCD3V2jfvqAWv4iByh3bybo719M+tE1Bw0zO9TMJllgCsGF8N90tZzsH7rgK3IAC/v5b+nrevSSfgRdPUMJhg//B/DbPq1RBlO3j4hIBlK3j4hIBjooun0qKyu9pqamr6shInJQmT9//gZ3T/nN8IMi/Gtqapg3b15fV0NE5KBiZonfrO+gbh8RkQyk8BcRyUB9Fv5mdoaZvWdmdWZ2XV/VQ0QkE/VJ+Ie3d70HOJPgHi+XmNnhfVEXEZFM1Fct/ylAnbsvcffdwCME9yMREZEPQV+F/zDi7+W9KizrYGZXWfDou3n19fUfauVERKKur8LfUpTFfdXY3e9z91p3r62q6s4DjEREpLv6apz/KuIf5FBN8MCPyPr9W2s4ZHApc5du4ojqMoaUFfDcwnVMGTWAH8x+n5MPqWLphkbGDizh3ElDWNWwk1+8upypoysYWlbI7HfWcephA3nrg61UFOcxYWgpyzY28tqKBsoKc3llyUYmVfdneHkhTy1YQ0VJHuu37WJsVQnvr9vG4UNKKc7P4bUVDRw2pJSpowfw/rrtZGcZE4eWUVaUy98WbWDS8DKefXMt7o6ZMWPCYN5Zs5XWNmfamAr+/H4967c24cC6rU2cd+Qw2tz52+INrN+6i4bG3RxbM4DWNmfHrhbGDerH++u2sa2phaFlBQwuK8AdRlYU8dSCNeRkGzlZxqYdzeRkGVubmpl5fA0Ahw7ux0//soTWNhhWXkhullFSkMOA4jxysrL466J68nKyaG2DCUNLWbetiaOG9+eNlVuorSln3dYmxlSVMH95A2+t3sKw/oVkZxkrNjbS1NzKpOr+DO1fyIiKIpbW76AgN4t1W3fxzJtryM/NYkxVCTMmDGLWwnUsqd9BU0srXz1tPPOWN3DC2EpWb97JglVbyMky1m9roqwwl7EDS9i0o5nDhvRj/vIGJo8o5+01W3mpbgP9i/IoLchhZcNOzjtyKDnZxqJ12/lg804GleZz4tgq5q9ooH9hLu+v20ZedhbnHjmUv9RtYNP23Zw0vpLWNuf1FZs5YWwlw8oLWbphB396bz1jqkpYs2Unr6/cTFlhLiMGFNPU3MrC1VuYPLKc5hanoiSP11duZmj/Qna1tJKfncWYgSWs3NRIcX4O4wf1492123B3ygpzqS4v4o/vrWfrzmYK87Jpam6lsiSf5lZnTFUxZYW5vLxkI0V52byxcgtHj+gPwIwJg1m+sZE1W3Z2/B6MqirmzIlDaHPnpy8uZXH9dgaXFVCYm011eSEvL9nIoNIC1m/dRW1NOe5QWZLH3GWbyM3OoqGxmZqKIlranPycLIrycnCcxl2tvLionqNHlLNjVwsbt+/iuNEVDCgOtvWwIaWs2byThau3cuEx1R3/FxzYuGM3ednG1p0trGxo5KRxVZQX5bJo/XZeXryRk8ZVMn9FA8V5ORwzspxVDY0cM7KcpxespaayiNKCXB57bRWHDSnlI+OqMIO/1W2gvCiP0sJclm/cwdqtTZQW5LJiUyPV5YXkZmdRv20X2VnGZ6aO4BevrGBz426OHTWAllZnYL98lm7cQe3IAbyxcjNjB5UwbXQFBbnZvZ5JfXJvn/CxdO8TPOj6A2Au8Cl3X5hq/traWu+NL3ntamll2YZGDhncr1vzv/h+PS+8u56bzpuQdp45SzexdMN2Tjl0EGu27GTjjt2cPL6Kh15dQWlhLqceOpAHX17Od37/bo/rLyKZ58jqMn7zxRPIykrVYdI5M5vv7rWppvVJt0/4jM9rgFnAO8Cj6YK/t7S0tvGJe19ixp0v8sHmnV0vAFx6/xx+9tIyfv7yMh7421LueOYdXlq8gWv+9zXOvOsvrGpo5B9/8jLfeOxNjr19Nuf96G9c/sBcvv7rBfzfJ97i2of/zrk//Ot+Df7TDh/EZcfXcPVHx3D+UcFjdT8+ec/lk389bXzaZaeNruh4XZC7d78K//fsw/juhZM63if+Xs6Y0L1H5N75yaO44oRRfPq4ER1lJ43b80jZcyYNoaaiiHEDS/j8R0YzYkARlSV5ceuoLMnn2JpyKoqD8pEVRYwfVBK3nlhTagakLB9Umt/x+uHPTU2afubEVE9zDFx4TDX/cdGRVJcXppw+Y8IgKorzePn6U9KuY18dMaws7n1Bbhbfu+hIHrjs2I6ywaUFHDaklP/8zDFJy592+CDu+NgRAJx3ZKpHMwfb96njRnD8mAounTaSvOyuf1+uPWUsD1x2LFX98pOmffOsQ5PKaiqKOHvSEE47fM/vTn5O6s/52unjU74GuP1jE7n+zOT1dyaxPl88eQzfPudwakeWx5WffEhVyt+DoWUFnf5fS2dY/0JuPX9Cyt/V0ZXFnDFhMJedULNPwd+Vg+Kunr3R8v/RC4v43nPBo0MfvGIKJ42rZFXDTlY2NLK9qYUxA0twd+Yvb2DswBKOGTmAmuue7o3qp7XgptOZdNNzAPzumhMxg6/88nXq1m9ndGUxp00YxE/+vKRj/se+cDyfuPclAH54ydE8tWA1P/mnPSd1d2fD9t1U9cvn5cUbWbZxB5dMGcGtT73Nf/91adLnL/u3s2ltc154dz0njatkW1MLi9Zvo6m5lSt+Ni9p3tWbd7J2axOTR5QnrcvdmfnAXF58v57RlcW88LWTWVy/na//egE3nzeBW373NnOWbQKCEP30cSOZOKyU/kV7gvytD7ZQVpjL8AFFHft+2b+d3ek+XLulieL8bPoV5OLubNyxm8qSIGza2pzF9dvZsH03Tc2tNDTu5uOTg6c/zlq4lsbdLeRlZ3P1/77GFSeM4tvn7hlt7O6Muj54UuVbN89ge1MLg8sKqFu/nd0tbby2ooHRVcVMG10R95kNO3Zz1t1/4YsfHUtRbjZf/dUbfGR8FQ9eMaVj3fOWbaKkIIdN23dz/NhK7v3TYmoqivjCQ8GDxB79/DRWNTTyr4++waXTRlKYlx33e/Dsl0/ioVeX87GjhzGmqoSsLOv4PQK45fwJXDqtBoDm1jYad7VSVpTbMX3O0k2MqixmW1MzX/jFa9x36TGMrCjumP7Kko3cNXsRD1wenDxa2pyS/Pge4tlvr+OzD87jqS+dyJX/M5d1W3dx/lFDKcrLprq8iKmjB3DMyD0n2bPu+gtvr9nKtaeO45PHDmdwaQFjvhns3798/aMMKM6jOOYzduxqITvLWLh6C5+492UAXvvWafQryGHrzmYqSvJZUr+dxt2tTAxPfhu27+o4Du3a2pzn31nHUcP7c/9fl/JP04JHSW9ubCbLjOsfX8BdFx/N8AFFHfVJ/J3bsauFtjAn+xUE+3FXSytNzW38+f16inKzmR6esN5ctYU/vreeE8ZWdNT7tgsmUlqYy7UP/52aiiL+38cncUR1WdI+3dXSStPuNnJzgqAvyut5r3xnLf+MCP/7XlzMHc/saX1/5xNHsK2phduefiftMm98+3SOvOW5tNP31tdOH8+i9dv57eurueKEURxRXcoFRw3rCJj2X7iW1jZa2ryjj2/+8k2s3tzE9MMG0erOxBtnxc3fHWu27OQj3/0jN547ge899x5Dygq56+KjGD8offfXtqZmXluxmZn3z6GqXz5zb5jerc9qbm0DIDehZdjS2sa2phaufeTv3HTeBMZUlXS6ntlvr6MwL5sTxqZuvfempuZW8rKzklpXNz25kEnVZR0njL3V1ub8+E91XDxlRFIopbJzd/BY38K8bJpb2/jxHxdz5UmjKM7Lpqm5jcO+/Xtysoy6O85KWrbmuqc5dHA/fvPFEyjIzcKs91uKiRp3t1CUl0PDjt0s3biDI6v7k52mhdrc2oY75MW05Guue5p++Tm8efOMtJ9Rt34b07//IgOK83jtW6f1+jbEeuLvH1BTWcxRw/v3yvqWbdhBTrZRXV7Euq1NHHfHH7jzk0dxwdHDul64l2R8+Ce24K89dRyvLNnInKWbelq1tH7zxeP52I+DVvqcb57KwNKCTuvWnTBvb43+y/TxfHn6uH2uW/vF3O544u8fcER1WZdhLfvf0wvWcMjgfowdmHwslm7YwYDiPMoKc1MseWBauamRorxsKjo5MW7f1cLEG2fx7xdO4qLa4Wnnk9QU/gnh368gh7zsLDbu2L3X6xpVWczSDTvIMmjzYJTJpOr+nH3EEI4cXkbd+u0AjB1YwhHhn+KdBftLdRsYWJrP2IHduwgtItJdnYX/QXFL5962ralln5e97YKJbNnZzG9f/4BZC9fxkfFVfOOMPReLjg77w92da08Zy+kT0l8kBDj+Q+jWEBFJpLt67qWS/BzOOmIIqzc3AcFY9FTMjH89/ZCOi1EiIgcShX83zAxHCADkZAd95WOqgtERH8YFSRGR3paR3T57qzBmyFX7KJZbL5jINaeM69YoDhGRA41a/ml88eQxHWOzJ4/YM/QrJxzK1q8gN+WoCxGRg0HGt/z7FeSkvACck2V8ZHwVr1x/KoPL9gzTTBy/LiJyMMr4JBtQnJd6QjgOPjb4YU+fv4jIwSzjw3/qqIqU5elupZGTlfG7TEQiIPJJ1tTc2un0Wy+YmLI8K803YHPV8heRCIh8+H/jsQWdTs9Lc9fAtC1/9fmLSAREPsleWbJxn5ZLd++bnP1wa1URkQ9b5MM/8bapqaS633hi9reP59doHxGJgsgnWUlB13c5fPTz05LKEvv8H//C8XznE0ekvWWtiMjBJPLj/Pt10vIfHd6iIdVF3MSMH1FRxIiKEUnziYgcjCLf8u9XkD78X/jqyQApW/OGWvgiEl2RD/90ff5PfenEjtcpw1/ZLyIRFv3wT9Pyjw33VF/cSjfOX0QkCiIf/oXhs3ATxYZ7doqgb78eICISRZEP/3QPqYxr2Sdk/5SaAZx8yMD9VicRkb4W/fBPk/6x2Z/Y5X9ImqdziYhERfTDP03bPzbw+xXk8tXTxsc9sUtEJMqiH/5pW/7xzf0vnTqOMeHDWdKdMEREoiIDwj9dyz/V2P72ZfZjhUREDgCRD/+2NEGe8i4N4QlB2S8iURf58E/b7ZPiG7wa2S8imSLy4d+WJv1TfYdraP/gkY01FUX7s0oiIn0u8jd2SycrRb/PKYcO4qHPHse00akf7SgiEhWRD//0F3xTz3/C2Mr9WBsRkQNDBnT7pC7XvXtEJJNFPvzTjdlX9ItIJot8+Kdr+ad7Rq+ISCaIfPinG+qppzGKSCaLfPin+8qW+vxFJJNFPvzb2lKXK/tFJJNFPvxjL/hednxNx2v1+YtIJutR+JvZv5vZu2a2wMx+Y2b9Y6Zdb2Z1Zvaemc2IKT8jLKszs+t68vndEXvBt7wor+O1+vxFJJP1tOX/PDDR3ScB7wPXA5jZ4cDFwATgDODHZpZtZtnAPcCZwOHAJeG8+036C75KfxHJXD0Kf3d/zt1bwrevANXh6/OBR9x9l7svBeqAKeFPnbsvcffdwCPhvPvN3tzSWUQkU/Rmn/8VwLPh62HAyphpq8KydOVJzOwqM5tnZvPq6+v3uVLpbs+s7BeRTNblvX3MbDYwOMWkG9z9t+E8NwAtwEPti6WY30l9skmZz+5+H3AfQG1t7T7fYj9dy1/hLyKZrMvwd/fpnU03s5nAOcCpvidpVwHDY2arBlaHr9OV7xe6t4+ISLKejvY5A/gGcJ67N8ZMehK42MzyzWwUMA6YA8wFxpnZKDPLI7go/GRP6tCVdH8yKPxFJJP19JbOPwLygefDcfOvuPs/u/tCM3sUeJugO+hqd28FMLNrgFlANnC/uy/sYR06Ffswl9i811BPEclkPQp/dx/bybTbgdtTlD8DPNOTz90rurGbiEiSyH/DN7bln27Mv4hIpol8+CcG/vf/8UgOG1LaN5URETlARP8xjsT3+X98cjUfn1zdyRIiItEX+ZZ/uqGeIiKZLPLhH9vtoz5/EZFABoS/El9EJFH0wz/mtUZ3iogEoh/+avmLiCSJfPi3qc9fRCRJ5MNfeS8ikiz64Z/m3j4iIpksA8K/r2sgInLgiXz4tyn9RUSSRD78lf0iIsmiH/665CsikiTy4a97+4iIJIt8+KvhLyKSLPK3dG5zZ+zAEorysrn42OFdLyAikgEiH/4ODCrN56HPTu3rqoiIHDAi3+3j7mTp210iInEiH/664Csikizy4Q9gavmLiMSJfPir4S8ikizy4Y87aveLiMSLfviju3mKiCSKfPir20dEJFn0w99Rt4+ISILIhz9otI+ISKLIh7/u6ikikizy4Q/q9hERSRT58NfDXEREkmVE+KvLX0QkXuTDP6D0FxGJFfnwV6+PiEiyyIc/qNtHRCRR5MPfdcVXRCRJ5MMf1OMvIpIoM8Jf6S8iEify4a9eHxGRZL0S/mb2NTNzM6sM35uZ3W1mdWa2wMwmx8w708wWhT8ze+Pzu6yfOn5EROLk9HQFZjYcOA1YEVN8JjAu/DkOuBc4zswGADcCtQSjMOeb2ZPu3tDTeqSje/uIiCTrjZb/D4CvEz+k/nzgQQ+8AvQ3syHADOB5d98UBv7zwBm9UIe09A1fEZFkPQp/MzsP+MDd30iYNAxYGfN+VViWrjzVuq8ys3lmNq++vr4n1VT4i4gk6LLbx8xmA4NTTLoB+CZweqrFUpR5J+XJhe73AfcB1NbW7nPfjTp9RESSdRn+7j49VbmZHQGMAt4IH5ZSDbxmZlMIWvTDY2avBlaH5ScnlP9pH+q9V3TBV0Qk3j53+7j7m+4+0N1r3L2GINgnu/ta4Eng0nDUz1Rgi7uvAWYBp5tZuZmVE/zVMKvnm9FpPffn6kVEDko9Hu2TxjPAWUAd0AhcDuDum8zsVmBuON8t7r5pP9UBCLt91PAXEYnTa+Eftv7bXztwdZr57gfu763P7Q5lv4hIvMh/w1dXfEVEkkU//AHTWE8RkTiRD381/EVEkkU//N3V5y8ikiDy4Q/6hq+ISKLIh7+6fUREkkU//F1DPUVEEkU+/EGjfUREEkU+/HU/fxGRZJEPf1C3j4hIosiHv+7rJiKSLDPCX01/EZE4kQ9/0P38RUQSZUT4i4hIvIwIf430FBGJF/nw15O8RESSRT/80fVeEZFEkQ9/ULePiEiiyIe/en1ERJJFPvxBQz1FRBJFPvx1bx8RkWTRD39Xn7+ISKLIhz8o/EVEEkU+/NXpIyKSLPLhH1DTX0QkVuTDX0M9RUSSRT78wdXnLyKSIAPCX50+IiKJIh/+6vYREUkW/fBHQz1FRBJFPvxBt3cQEUkU+fDX/fxFRJJFPvxB3T4iIokiH/5q94uIJIt++LuGeoqIJIp8+AOY+n1EROJEPvx1wVdEJFnkw19ERJL1OPzN7Etm9p6ZLTSz78aUX29mdeG0GTHlZ4RldWZ2XU8/vytq94uIJMvpycJm9lHgfGCSu+8ys4Fh+eHAxcAEYCgw28zGh4vdA5wGrALmmtmT7v52T+rRKT3JS0QkSY/CH/gC8G/uvgvA3deH5ecDj4TlS82sDpgSTqtz9yUAZvZIOO/+C3/0DV8RkUQ97fYZD5xkZq+a2Z/N7NiwfBiwMma+VWFZuvIkZnaVmc0zs3n19fX7XEF1+4iIJOuy5W9ms4HBKSbdEC5fDkwFjgUeNbPRpB5a76Q+2aTMZ3e/D7gPoLa2tkcZrm4fEZF4XYa/u09PN83MvgA87sF4yjlm1gZUErToh8fMWg2sDl+nK98vNNRTRCRZT7t9ngBOAQgv6OYBG4AngYvNLN/MRgHjgDnAXGCcmY0yszyCi8JP9rAOnXL0DV8RkUQ9veB7P3C/mb0F7AZmhn8FLDSzRwku5LYAV7t7K4CZXQPMArKB+919YQ/r0CV1+4iIxOtR+Lv7buAzaabdDtyeovwZ4JmefO7eUK+PiEiyjPiGr+7tIyISL/Lh7xrsKSKSJPrhr1s6i4gkiXz4A0p/EZEEkQ9/dfqIiCSLfPjjurePiEii6Ic/GucvIpIo8uGv0T4iIskiH/6g670iIokiH/76hq+ISLLohz/q8xcRSRT58AeN9hERSRT58Nf9/EVEkkU+/EHdPiIiiSIf/mr3i4gki37468ZuIiJJIh/+gPp9REQSZEb4i4hInIwIf7X7RUTiRTr8NcxTRCS1iId/8K+6/EVE4kU6/NvpG74iIvEiHf7q9BERSS3S4d9O3T4iIvEiHf664Csiklq0wz/8Vw1/EZF4kQ7/dur2ERGJF+nwV6+PiEhqkQ7/dqamv4hInEiHv2uwp4hIStEOf2W/iEhKkQ7/dur1ERGJlxHhLyIi8SId/h03dtNIfxGROJEO/3bq9hERiRfp8NdoHxGR1CId/u3U8BcRiRfp8NdQTxGR1KId/uG/6vMXEYnXo/A3s6PM7BUze93M5pnZlLDczOxuM6szswVmNjlmmZlmtij8mdnTDehWPdXxIyISJ6eHy38XuNndnzWzs8L3JwNnAuPCn+OAe4HjzGwAcCNQS9Awn29mT7p7Qw/rkZLu5y8iklpPu30cKA1flwGrw9fnAw964BWgv5kNAWYAz7v7pjDwnwfO6GEduqRuHxGReD1t+X8FmGVm3yM4kRwflg8DVsbMtyosS1eexMyuAq4CGDFixD5VTu1+EZHUugx/M5sNDE4x6QbgVOBf3P0xM/tH4L+B6aQeXemdlCcXut8H3AdQW1u7TzmuXh8RkdS6DH93n55umpk9CHw5fPsr4CRsHDYAAAV5SURBVL/C16uA4TGzVhN0Ca0iuCYQW/6nbtd2H+l+/iIi8Xra578a+Ifw9SnAovD1k8Cl4aifqcAWd18DzAJON7NyMysHTg/L9g+1/EVEUuppn//ngLvMLAdoIuyjB54BzgLqgEbgcgB332RmtwJzw/lucfdNPaxDl9TuFxGJ16Pwd/e/AsekKHfg6jTL3A/c35PP7S7d20dEJLVof8O3/ZbOavqLiMSJdPi3U/aLiMSLdPir00dEJLVIh387DfUUEYkX6fDXvX1ERFKLdPjn5WRx9hFDGFlR1NdVERE5oPR0nP8BrV9BLvd8enLXM4qIZJhIt/xFRCQ1hb+ISAZS+IuIZCCFv4hIBlL4i4hkIIW/iEgGUviLiGQghb+ISAayg+EWCGZWDyzvwSoqgQ29VJ2DhbY5+jJte0HbvLdGuntVqgkHRfj3lJnNc/favq7Hh0nbHH2Ztr2gbe5N6vYREclACn8RkQyUKeF/X19XoA9om6Mv07YXtM29JiP6/EVEJF6mtPxFRCSGwl9EJANFOvzN7Awze8/M6szsur6uT28xs+Fm9kcze8fMFprZl8PyAWb2vJktCv8tD8vNzO4O98MCMzton3BjZtlm9nczeyp8P8rMXg23+ZdmlheW54fv68LpNX1Z731lZv3N7Ndm9m54vKdF/Tib2b+Ev9dvmdnDZlYQteNsZveb2XozeyumbK+Pq5nNDOdfZGYz96YOkQ1/M8sG7gHOBA4HLjGzw/u2Vr2mBfiqux8GTAWuDrftOuAP7j4O+EP4HoJ9MC78uQq498Ovcq/5MvBOzPvvAD8It7kBuDIsvxJocPexwA/C+Q5GdwG/d/dDgSMJtj2yx9nMhgHXArXuPhHIBi4mesf5Z8AZCWV7dVzNbABwI3AcMAW4sf2E0S3uHskfYBowK+b99cD1fV2v/bStvwVOA94DhoRlQ4D3wtc/AS6Jmb9jvoPpB6gO/1OcAjwFGME3H3MSjzkwC5gWvs4J57O+3oa93N5SYGlivaN8nIFhwEpgQHjcngJmRPE4AzXAW/t6XIFLgJ/ElMfN19VPZFv+7PklarcqLIuU8M/co4FXgUHuvgYg/HdgOFtU9sWdwNeBtvB9BbDZ3VvC97Hb1bHN4fQt4fwHk9FAPfBA2NX1X2ZWTISPs7t/AHwPWAGsIThu84n2cW63t8e1R8c7yuFvKcoiNa7VzEqAx4CvuPvWzmZNUXZQ7QszOwdY7+7zY4tTzOrdmHawyAEmA/e6+9HADvZ0BaRy0G9z2G1xPjAKGAoUE3R7JIrSce5Kum3s0bZHOfxXAcNj3lcDq/uoLr3OzHIJgv8hd388LF5nZkPC6UOA9WF5FPbFCcB5ZrYMeISg6+dOoL+Z5YTzxG5XxzaH08uATR9mhXvBKmCVu78avv81wckgysd5OrDU3evdvRl4HDieaB/ndnt7XHt0vKMc/nOBceEogTyCi0ZP9nGdeoWZGfDfwDvu/v2YSU8C7Vf8ZxJcC2gvvzQcNTAV2NL+5+XBwt2vd/dqd68hOJYvuPungT8CF4azJW5z+764MJz/oGoRuvtaYKWZHRIWnQq8TYSPM0F3z1QzKwp/z9u3ObLHOcbeHtdZwOlmVh7+xXR6WNY9fX3RYz9fUDkLeB9YDNzQ1/Xpxe06keDPuwXA6+HPWQR9nX8AFoX/DgjnN4KRT4uBNwlGUvT5dvRg+08GngpfjwbmAHXAr4D8sLwgfF8XTh/d1/Xex209CpgXHusngPKoH2fgZuBd4C3g50B+1I4z8DDBNY1mghb8lftyXIErwm2vAy7fmzro9g4iIhkoyt0+IiKShsJfRCQDKfxFRDKQwl9EJAMp/EVEMpDCX0QkAyn8RUQy0P8HCLIe7YxH4gsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def q_learning(env, num_episodes, discount_factor=1.0, alpha=0.5, epsilon=0.1, Q=None):\n",
    "    \"\"\"\n",
    "    Q-Learning algorithm: Off-policy TD control. Finds the optimal greedy policy\n",
    "    while following an epsilon-greedy policy\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        epsilon: Probability to sample a random action. Float between 0 and 1.\n",
    "        Q: hot-start the algorithm with a Q value function (optional)\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is the optimal action-value function, a dictionary mapping state -> action values.\n",
    "        stats is a list of tuples giving the episode lengths and rewards.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The final action-value function.\n",
    "    # A nested dictionary that maps state -> (action -> action-value).\n",
    "    if Q is None:\n",
    "        Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    # Keeps track of useful statistics\n",
    "    stats = []\n",
    "    \n",
    "    # The policy we're following\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)\n",
    "    \n",
    "\n",
    "    for i_episode in tqdm(range(num_episodes)):\n",
    "        i = 0\n",
    "        R = 0\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        s = env.reset()\n",
    "        end = False\n",
    "        while not end:\n",
    "            a = policy(s)\n",
    "            s_new,r,end,prob = env.step(a)\n",
    "            \n",
    "            a_max = np.argmax(Q[s_new])\n",
    "            Q[s][a] = Q[s][a] + alpha * (r + discount_factor*Q[s_new][a_max] - Q[s][a])\n",
    "            s = s_new\n",
    "            i += 1\n",
    "            R += r\n",
    "        \n",
    "        stats.append((i, R))\n",
    "    episode_lengths, episode_returns = zip(*stats)\n",
    "    return Q, (episode_lengths, episode_returns)\n",
    "\n",
    "Q_q_learning, (episode_lengths_q_learning, episode_returns_q_learning) = q_learning(env, 1000)\n",
    "\n",
    "# We will help you with plotting this time\n",
    "plt.plot(episode_lengths_q_learning)\n",
    "plt.title('Episode lengths Q-learning')\n",
    "plt.show()\n",
    "plt.plot(episode_returns_q_learning)\n",
    "plt.title('Episode returns Q-learning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f695c6e9d66afd4fc7a49b565419ba5d",
     "grade": false,
     "grade_id": "cell-9f1fcee44ba712c2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now compare the episode returns while learning for Q-learning and Sarsa (maybe run some more iterations?), by plotting the returns for both algorithms in a single plot, like in the book, Example 6.6. In order to be able to compare them, you may want to zoom in on the y-axis and smooth the returns (e.g. plotting the $n$ episode average instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3c1a110fe85c38220afed145a8cf09bc",
     "grade": true,
     "grade_id": "cell-69ed62a52a44dd78",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                       | 0/100000 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "  1%|█                                                                         | 1495/100000 [00:01<01:05, 1493.59it/s]\n",
      "\n",
      "\n",
      "\n",
      "  3%|██▎                                                                       | 3192/100000 [00:02<01:02, 1549.02it/s]\n",
      "\n",
      "\n",
      "\n",
      "  5%|███▋                                                                      | 4983/100000 [00:03<00:58, 1614.30it/s]\n",
      "\n",
      "\n",
      "\n",
      "  6%|████▊                                                                     | 6495/100000 [00:04<00:59, 1581.90it/s]\n",
      "\n",
      "\n",
      "\n",
      "  8%|██████                                                                    | 8236/100000 [00:05<00:56, 1626.22it/s]\n",
      "\n",
      "\n",
      "\n",
      " 10%|███████▎                                                                 | 10063/100000 [00:06<00:53, 1681.55it/s]\n",
      "\n",
      "\n",
      "  1%|█                                                                       | 14370/1000000 [00:23<09:03, 1813.11it/s]\n",
      "\n",
      "\n",
      "\n",
      " 12%|████████▌                                                                | 11665/100000 [00:07<00:53, 1656.72it/s]\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████████▉                                                               | 13549/100000 [00:08<00:50, 1718.60it/s]\n",
      "\n",
      "\n",
      "\n",
      " 15%|███████████▏                                                             | 15310/100000 [00:09<00:48, 1730.76it/s]\n",
      "\n",
      "\n",
      "\n",
      " 17%|████████████▌                                                            | 17136/100000 [00:10<00:47, 1757.77it/s]\n",
      "\n",
      "\n",
      "\n",
      " 19%|█████████████▊                                                           | 18867/100000 [00:11<00:46, 1749.33it/s]\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████████████                                                          | 20592/100000 [00:12<00:45, 1729.89it/s]\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████████████▎                                                        | 22306/100000 [00:13<00:46, 1657.87it/s]\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████████████▍                                                       | 23959/100000 [00:14<00:46, 1627.41it/s]\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████████████▊                                                      | 25753/100000 [00:15<00:44, 1673.93it/s]\n",
      "\n",
      "\n",
      "\n",
      " 28%|████████████████████▎                                                    | 27747/100000 [00:16<00:41, 1758.52it/s]\n",
      "\n",
      "\n",
      "\n",
      " 30%|█████████████████████▌                                                   | 29518/100000 [00:17<00:41, 1716.92it/s]\n",
      "\n",
      "\n",
      "\n",
      " 31%|██████████████████████▉                                                  | 31343/100000 [00:18<00:39, 1747.71it/s]\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████████████████▏                                                | 33100/100000 [00:19<00:38, 1724.21it/s]\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████████████████▍                                               | 34899/100000 [00:20<00:37, 1745.72it/s]\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████████████████▊                                              | 36651/100000 [00:21<00:36, 1728.70it/s]\n",
      "\n",
      "\n",
      "\n",
      " 38%|████████████████████████████                                             | 38446/100000 [00:22<00:35, 1748.06it/s]\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████████████████▎                                           | 40198/100000 [00:23<00:34, 1735.94it/s]\n",
      "\n",
      "\n",
      "\n",
      " 42%|██████████████████████████████▌                                          | 41937/100000 [00:24<00:37, 1558.10it/s]\n",
      "\n",
      "\n",
      "\n",
      " 44%|███████████████████████████████▊                                         | 43532/100000 [00:25<00:37, 1507.09it/s]\n",
      "\n",
      "\n",
      "\n",
      " 45%|████████████████████████████████▉                                        | 45069/100000 [00:27<00:39, 1384.37it/s]\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████████████████████▉                                       | 46494/100000 [00:28<00:41, 1293.90it/s]\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████████████████████▉                                      | 47828/100000 [00:29<00:40, 1280.98it/s]\n",
      "\n",
      "\n",
      "\n",
      " 49%|███████████████████████████████████▉                                     | 49293/100000 [00:30<00:38, 1330.93it/s]\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████████████████████████████████████▎                                   | 51099/100000 [00:31<00:33, 1444.68it/s]\n",
      "\n",
      "\n",
      "\n",
      " 53%|██████████████████████████████████████▌                                  | 52810/100000 [00:32<00:31, 1515.14it/s]\n",
      "\n",
      "\n",
      "\n",
      " 54%|███████████████████████████████████████▋                                 | 54367/100000 [00:33<00:31, 1445.62it/s]\n",
      "\n",
      "\n",
      "\n",
      " 56%|████████████████████████████████████████▉                                | 56091/100000 [00:34<00:28, 1518.94it/s]\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████████████████████████                               | 57645/100000 [00:35<00:28, 1503.69it/s]\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████████████████████████▎                             | 59287/100000 [00:36<00:26, 1542.56it/s]\n",
      "\n",
      "\n",
      "\n",
      " 61%|████████████████████████████████████████████▍                            | 60850/100000 [00:37<00:25, 1544.93it/s]\n",
      "\n",
      "\n",
      "\n",
      " 62%|█████████████████████████████████████████████▌                           | 62414/100000 [00:38<00:24, 1550.33it/s]\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████████████████████████████████████████████▋                          | 64025/100000 [00:39<00:22, 1567.62it/s]\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████████████████████████████                         | 65826/100000 [00:40<00:20, 1630.79it/s]\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████████████████████████████▎                       | 67469/100000 [00:41<00:20, 1609.00it/s]\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████████████████████████████▍                      | 69154/100000 [00:42<00:18, 1630.84it/s]\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████████████████████████████▊                     | 71004/100000 [00:43<00:17, 1690.75it/s]\n",
      "\n",
      "\n",
      "\n",
      " 73%|█████████████████████████████████████████████████████▏                   | 72906/100000 [00:44<00:15, 1748.84it/s]\n",
      "\n",
      "\n",
      "\n",
      " 75%|██████████████████████████████████████████████████████▋                  | 74923/100000 [00:45<00:13, 1821.46it/s]\n",
      "\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████████████████████████████                 | 76825/100000 [00:46<00:12, 1844.57it/s]\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████████████████████████████▌               | 78858/100000 [00:47<00:11, 1897.23it/s]\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████████████████████████████▉              | 80768/100000 [00:48<00:10, 1861.48it/s]\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████████████████████████████████▎            | 82640/100000 [00:50<00:09, 1847.85it/s]\n",
      "\n",
      "\n",
      "\n",
      " 84%|█████████████████████████████████████████████████████████████▋           | 84496/100000 [00:51<00:08, 1841.76it/s]\n",
      "\n",
      "\n",
      "\n",
      " 86%|███████████████████████████████████████████████████████████████          | 86389/100000 [00:52<00:07, 1856.40it/s]\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████████▍        | 88250/100000 [00:53<00:06, 1786.58it/s]\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████▋       | 90045/100000 [00:54<00:05, 1766.48it/s]\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████▏     | 91976/100000 [00:55<00:04, 1812.56it/s]\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████████████████████████████████████▌    | 93989/100000 [00:56<00:03, 1867.99it/s]\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████████████████████████████████████▉   | 95867/100000 [00:57<00:02, 1868.44it/s]\n",
      "\n",
      "\n",
      "\n",
      " 98%|███████████████████████████████████████████████████████████████████████▍ | 97809/100000 [00:58<00:01, 1889.46it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████▊| 99704/100000 [00:59<00:00, 1884.97it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [00:59<00:00, 1684.19it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                       | 0/100000 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "  2%|█▏                                                                        | 1563/100000 [00:01<01:03, 1562.40it/s]\n",
      "\n",
      "\n",
      "\n",
      "  3%|██▍                                                                       | 3268/100000 [00:02<01:00, 1602.60it/s]\n",
      "\n",
      "\n",
      "\n",
      "  5%|███▋                                                                      | 5058/100000 [00:03<00:57, 1654.38it/s]\n",
      "\n",
      "\n",
      "\n",
      "  7%|████▉                                                                     | 6641/100000 [00:04<00:57, 1632.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "  8%|██████▏                                                                   | 8442/100000 [00:05<00:54, 1678.24it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▍                                                                 | 10231/100000 [00:06<00:52, 1709.04it/s]\n",
      "\n",
      "\n",
      "\n",
      " 12%|████████▋                                                                | 11958/100000 [00:07<00:51, 1713.92it/s]\n",
      "\n",
      "\n",
      "\n",
      " 14%|██████████▏                                                              | 13893/100000 [00:08<00:48, 1774.65it/s]\n",
      "\n",
      "\n",
      "\n",
      " 16%|███████████▍                                                             | 15587/100000 [00:09<00:48, 1727.23it/s]\n",
      "\n",
      "\n",
      "\n",
      " 17%|████████████▌                                                            | 17260/100000 [00:10<00:48, 1705.65it/s]\n",
      "\n",
      "\n",
      "\n",
      " 19%|█████████████▉                                                           | 19177/100000 [00:11<00:45, 1763.67it/s]\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████████████▍                                                         | 21170/100000 [00:12<00:43, 1826.48it/s]\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████████████▊                                                        | 22988/100000 [00:13<00:44, 1717.17it/s]\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████████████▎                                                      | 25007/100000 [00:14<00:41, 1797.66it/s]\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████████████▋                                                     | 26956/100000 [00:15<00:39, 1840.33it/s]\n",
      "\n",
      "\n",
      "\n",
      " 29%|█████████████████████                                                    | 28893/100000 [00:16<00:38, 1868.13it/s]\n",
      "\n",
      "\n",
      "\n",
      " 31%|██████████████████████▍                                                  | 30819/100000 [00:17<00:36, 1884.67it/s]\n",
      "\n",
      "\n",
      "\n",
      " 33%|███████████████████████▉                                                 | 32753/100000 [00:18<00:35, 1898.78it/s]\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████████████████▎                                               | 34658/100000 [00:19<00:35, 1858.87it/s]\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████████████████▋                                              | 36523/100000 [00:20<00:34, 1859.98it/s]\n",
      "\n",
      "\n",
      "\n",
      " 38%|████████████████████████████                                             | 38387/100000 [00:21<00:34, 1812.11it/s]\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████████████████▍                                           | 40341/100000 [00:22<00:32, 1852.45it/s]\n",
      "\n",
      "\n",
      "\n",
      " 42%|██████████████████████████████▊                                          | 42200/100000 [00:23<00:31, 1849.34it/s]\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████████████████████▏                                        | 44145/100000 [00:24<00:29, 1876.81it/s]\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████████████████████▌                                       | 46026/100000 [00:25<00:29, 1855.21it/s]\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████████████████████▉                                      | 47922/100000 [00:26<00:27, 1866.96it/s]\n",
      "\n",
      "\n",
      "\n",
      " 50%|████████████████████████████████████▍                                    | 49874/100000 [00:27<00:26, 1891.59it/s]\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████████████████████▊                                   | 51830/100000 [00:28<00:25, 1910.42it/s]\n",
      "\n",
      "\n",
      "\n",
      " 54%|███████████████████████████████████████▏                                 | 53743/100000 [00:29<00:24, 1906.36it/s]\n",
      "\n",
      "\n",
      "\n",
      " 56%|████████████████████████████████████████▋                                | 55651/100000 [00:30<00:23, 1892.36it/s]\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████████████████████████                               | 57545/100000 [00:31<00:22, 1857.56it/s]\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████████████████████████▎                             | 59405/100000 [00:32<00:22, 1835.26it/s]\n",
      "\n",
      "\n",
      "\n",
      " 61%|████████████████████████████████████████████▋                            | 61243/100000 [00:33<00:21, 1812.79it/s]\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████████████████████████                           | 63184/100000 [00:34<00:19, 1849.10it/s]\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████████████████████████▍                         | 65067/100000 [00:35<00:18, 1859.10it/s]\n",
      "\n",
      "\n",
      "\n",
      " 67%|████████████████████████████████████████████████▊                        | 66929/100000 [00:36<00:18, 1784.71it/s]\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████████████████████████████▏                      | 68722/100000 [00:37<00:17, 1763.99it/s]\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████████████████████████████▍                     | 70493/100000 [00:38<00:17, 1709.34it/s]\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████████████████████████████▊                    | 72352/100000 [00:39<00:15, 1751.37it/s]\n",
      "\n",
      "\n",
      "\n",
      " 74%|██████████████████████████████████████████████████████▎                  | 74391/100000 [00:40<00:14, 1828.38it/s]\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████████████████████████████████████████████████████▋                 | 76291/100000 [00:41<00:12, 1848.88it/s]\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████████████████████████████████                | 78151/100000 [00:42<00:11, 1847.36it/s]\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████████████████████████████████▍              | 80006/100000 [00:44<00:11, 1786.68it/s]\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████████████████████████████▋             | 81803/100000 [00:45<00:10, 1685.44it/s]\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████████████████████████████████▉            | 83507/100000 [00:46<00:09, 1655.95it/s]\n",
      "\n",
      "\n",
      "\n",
      " 85%|██████████████████████████████████████████████████████████████▏          | 85178/100000 [00:47<00:08, 1658.98it/s]\n",
      "\n",
      "\n",
      "\n",
      " 87%|███████████████████████████████████████████████████████████████▍         | 86847/100000 [00:48<00:07, 1657.15it/s]\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████████▋        | 88644/100000 [00:49<00:06, 1696.26it/s]\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████▉       | 90393/100000 [00:50<00:05, 1711.40it/s]\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████▎     | 92192/100000 [00:51<00:04, 1736.39it/s]\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████████████████████████████████████▋    | 94066/100000 [00:52<00:03, 1775.16it/s]\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████████████████████████████████████▉   | 95859/100000 [00:53<00:02, 1780.43it/s]\n",
      "\n",
      "\n",
      "\n",
      " 98%|███████████████████████████████████████████████████████████████████████▍ | 97810/100000 [00:54<00:01, 1828.09it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████▋| 99650/100000 [00:55<00:00, 1831.35it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [00:55<00:00, 1798.97it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x159ca8acc50>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "no_episodes = 100000\n",
    "\n",
    "Q_q_learning, (episode_lengths_q_learning, episode_returns_q_learning) = q_learning(env, no_episodes)\n",
    "Q_sarsa, (episode_lengths_sarsa, episode_returns_sarsa) = sarsa(env, no_episodes)\n",
    "\n",
    "q_learning_avreages = []\n",
    "sarsa_avreages = []\n",
    "\n",
    "#smothing\n",
    "n = 1000\n",
    "for i in range(no_episodes):\n",
    "    if no_episodes - n - i >= 0:\n",
    "        q_avreage = np.sum(episode_returns_q_learning[i:i+n]) / n\n",
    "        sarsa_avreage = np.sum(episode_returns_sarsa[i:i+n]) / n\n",
    "    else:\n",
    "        right = no_episodes - i\n",
    "        left = n - right\n",
    "        q_avreage = (np.sum(episode_returns_q_learning[i:i+right]) + np.sum(episode_returns_q_learning[i-left:i]))/n\n",
    "        sarsa_avreage = (np.sum(episode_returns_sarsa[i:i+right]) + np.sum(episode_returns_sarsa[i-left:i]))/n\n",
    "    q_learning_avreages.append(q_avreage)\n",
    "    sarsa_avreages.append(sarsa_avreage)\n",
    "\n",
    "plt.plot(q_learning_avreages, label=\"Q learnig\")\n",
    "plt.plot(sarsa_avreages, label=\"Sarsa\")\n",
    "plt.ylim(-25, 0)\n",
    "\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed2526b0c0f17f055f520f67072c59ac",
     "grade": false,
     "grade_id": "cell-7ef9de74c57a4f0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Which algorithm achieves higher return during learning? How does this compare to Example 6.6 from the book? Try to explain your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a3357293c326223f2a02cae0f38ca24a",
     "grade": true,
     "grade_id": "cell-7acf9de8c94a171f",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2f954f745662334010f6fb0fcfd9896",
     "grade": false,
     "grade_id": "cell-316d3cfd35d55387",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "After we have learned the policy, we do not care about exploration any more and we may switch to a deterministic (greedy) policy instead. If we evaluate this for both Sarsa and Q-learning (actually, for Q-learning the learned policy is already deterministic), which policy would you expect to perform better? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "011f8038ac100bfdc5e40b78c1bdc2f8",
     "grade": true,
     "grade_id": "cell-ea5058e6f352d717",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57ab54058d433e24421d1e1224a9bc87",
     "grade": false,
     "grade_id": "cell-8bcc6f5839a36860",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Please run the experiments to test your hypothesis (print or plot your results). How many runs do you need to evaluate the policy? Note: without learning, the order of the episodes is not relevant so a normal `plt.plot` may not be the most appropriate choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "149c39efef43f1807d2b06e6bc50bf95",
     "grade": true,
     "grade_id": "cell-55f9d1767bb7c011",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e70351edfa59760104962f08d541557b",
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## 2. Deep Q-Network (DQN) (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e27fe8f72a248bbcf1f7a21e5550e657",
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\rl2019\\lib\\site-packages\\gym\\envs\\registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "??env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close()  # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "11a9c014ee5fbe790ce999428cc22658",
     "grade": false,
     "grade_id": "cell-2d83f70e62b99520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9692b7acb09d018d9f80ce95685b81d5",
     "grade": false,
     "grade_id": "cell-bf2ac21267daffbb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Can you think of a way in which we can still use a tabular approach? Why would this work and can you think of an example problem where this would not work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3ffce6fca4071a1b543186db1b74cc98",
     "grade": true,
     "grade_id": "cell-b0fa2cb0c2cd2a63",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2c5bddd080e12cb076c845d093a70ed7",
     "grade": false,
     "grade_id": "cell-0b3162496f5e6cf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Implement Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84b9c38718c952ef8e62486fc9bf5e4a",
     "grade": false,
     "grade_id": "cell-96a86bcfa1ebc84a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ef7d14363dc2aa4beb638856c57a58c",
     "grade": false,
     "grade_id": "cell-216429a5dccf8a0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.l1(x)\n",
    "        a1 = F.relu(out1)\n",
    "        out2 = self.l2(a1)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b9a48f9aee9ebc46da01c6f11cd789a",
     "grade": true,
     "grade_id": "cell-00ce108d640a5942",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "model = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complaints when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(model(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c7227d52671b410864319222a98e27d1",
     "grade": false,
     "grade_id": "cell-ca77eae2e62180cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b3265bef151a12fe6969c378af76be2",
     "grade": false,
     "grade_id": "cell-b5b012e42dd2029e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "What could be a problem with doing gradient updates on a sequence of state, action pairs $((s_t, a_t), (s_{t+1}, a_{t+1}) ...)$ observed while interacting with the environment? How will using *experience replay* help to overcome this (potential problem)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "75e1a8b00b2bfa9b7dd8805b371c6a4e",
     "grade": true,
     "grade_id": "cell-70a2e59541668a25",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b3bbd8aaf3aade515736d0d07917a61",
     "grade": false,
     "grade_id": "cell-2c1d117a1a75fd69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now implement the `push` function that adds a transition to the replay buffer, and the sample function that returns a batch of samples. It should keep at most the maximum number of transitions. Also implement the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c64677cbc7efad32a949783b7c9b53b7",
     "grade": false,
     "grade_id": "cell-a3cc876e51eb157f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        self.memory.append(transition)\n",
    "        if len(self.memory) > self.capacity:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6865749b3a8810bdaaf1604a9cea42e7",
     "grade": true,
     "grade_id": "cell-3b90135921c4da76",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([-0.01303166, -0.04270197, -0.04540492,  0.04584364]), 0, 1.0, array([-0.0138857 , -0.23714443, -0.04448805,  0.32386226]), False)]\n"
     ]
    }
   ],
   "source": [
    "capacity = 10\n",
    "memory = ReplayMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "354743bd76d6ba43d95b5b177443a202",
     "grade": false,
     "grade_id": "cell-88f67e3c051da6a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3 $\\epsilon$psilon greedy policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61d26d0dec0133f2aa737ed4711d6e08",
     "grade": false,
     "grade_id": "cell-aa3c7d1b3000f697",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "270ab31d4bb29dc9a05223c16a4967a7",
     "grade": false,
     "grade_id": "cell-5789e7a792108576",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_epsilon(it):\n",
    "    # YOUR CODE HERE\n",
    "    return max(0.05, 1 - it/1000 * 0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b1a81dd07e1b7a98d2cd06ebc171ebdd",
     "grade": true,
     "grade_id": "cell-40e66db45e742b2e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x159c9f2bf98>]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84685c23e4eb899d7fed3a87b7f8915e",
     "grade": false,
     "grade_id": "cell-a8b604c9998c6c3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function that takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon (which we will pass later). Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Unlike numpy, PyTorch has no argmax function, but Google is your friend... Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "882f51819100c850120e73340aec387d",
     "grade": false,
     "grade_id": "cell-878ad3a637cfb51c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_action(model, state, epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    state = torch.tensor(state).float()\n",
    "    q = model(state)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if random.random() < epsilon:\n",
    "            return random.randrange(0,len(q))\n",
    "        return torch.argmax(q).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21f939075cb0c8dde152dabf47568a9d",
     "grade": true,
     "grade_id": "cell-e895338d56bee477",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "a = select_action(model, s, 0.05)\n",
    "assert not torch.is_tensor(a)\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e66ac58d65710439ddf7cdf19a50cd8c",
     "grade": false,
     "grade_id": "cell-ec5e94e0b03f8aec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4839aac72a80552046ebecc40c1615cf",
     "grade": false,
     "grade_id": "cell-d1a12cc97386fe56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
    "\n",
    "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c466ee49add35cb1ec6a3e4a85f733c9",
     "grade": false,
     "grade_id": "cell-6c45485324b40081",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_q_val(model, state, action):\n",
    "    # YOUR CODE HERE\n",
    "    q = model(state)\n",
    "    q_a = q.gather(1, action.view(-1,1))\n",
    "    return q_a\n",
    "\n",
    "\n",
    "def compute_target(model, reward, next_state, done, discount_factor):\n",
    "    # done is a boolean (vector) that indicates if next_state is terminal (episode is done)\n",
    "    # YOUR CODE HERE\n",
    "    q = model(next_state)\n",
    "    q_max = torch.max(q) # max action\n",
    "    q_max = (1 - done.float()) * q_max # make zero, terminal states\n",
    "    return reward + discount_factor * q_max\n",
    "\n",
    "def train(model, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)\n",
    "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_val(model, state, action)\n",
    "    \n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_target(model, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "877c400001292b619e6871c1366524b9",
     "grade": true,
     "grade_id": "cell-b060b822eec4282f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-261-0c54261ded69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Now let's see if it works\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-260-a139805a9f95>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, memory, optimizer, batch_size, discount_factor)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# convert to PyTorch and define types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print (loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bd2841924b22cdf411348a0eb6080502",
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06dd71aae5c3c699f2b707b348a88107",
     "grade": false,
     "grade_id": "cell-36b8a04b393d8104",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c3f61b2ca270d84ab9b28d989dd65d4c",
     "grade": false,
     "grade_id": "cell-540a7d50ecc1d046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def run_episodes(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        epsilon = get_epsilon(i)\n",
    "        for i in range(batch_size):\n",
    "            action = select_action(model, state, epsilon)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            memory.push((state, action, reward, next_state, done))\n",
    "            if done == True:\n",
    "                state = env.reset()\n",
    "                \n",
    "        train(model, memory, optimizer, batch_size, discount_factor)\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\rl2019\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(10000)\n",
    "num_hidden = 128\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducability\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "model = QNetwork(num_hidden)\n",
    "\n",
    "episode_durations = run_episodes(train, model, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "70d16eb61eae34605e8d7813a70a604a",
     "grade": true,
     "grade_id": "cell-928ecc11ed5c43d8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title('Episode durations per episode')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f5e85e8aa15e9cb9117b17265435eae",
     "grade": false,
     "grade_id": "cell-6607b79e73a101a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Policy Gradient (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "951b88e9cd8396d088d3f80e6da9690c",
     "grade": false,
     "grade_id": "cell-083fe71da94aa7aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "So we have spent a lot of time working on *value based* methods. We will now switch to *policy based* methods, i.e. learn a policy directly rather than learn a value function from which the policy follows. Mention two advantages of using a policy based method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a5c1f505cb22eca6eb3b8213ff23e60f",
     "grade": true,
     "grade_id": "cell-134510705650d5ac",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "233ca94abc32f0e510c5d8a164206d05",
     "grade": false,
     "grade_id": "cell-76a10fe31897025f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 3.1 Policy Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2bc16b45e6145226b8a6f5117003b7f5",
     "grade": false,
     "grade_id": "cell-34f0712f792bbcca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to do so, we will implement a Policy network. Although in general this does not have to be the case, we will use an architecture very similar to the Q-network (two layers with ReLU activation for the hidden layer). Since we have discrete actions, our model will output one value per action, where each value represents the (normalized!) log-probability of selecting that action. *Use the (log-)softmax activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "155baf230fd6deb5f6ccf93138fa3419",
     "grade": false,
     "grade_id": "cell-6a31440f9477f963",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3cb94e04b03fa4b663bcf38a96ef656d",
     "grade": true,
     "grade_id": "cell-9d280fe6520edc91",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "model = PolicyNetwork(num_hidden)\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "log_p = model(x)\n",
    "\n",
    "# Does the outcome make sense?\n",
    "print(log_p.exp())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8b0ff099a335c248a91df00e975494d0",
     "grade": false,
     "grade_id": "cell-35294ca4eda15b11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 3.2 Monte Carlo REINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "93ed9cbcf70541f5a04709ee89a16e78",
     "grade": false,
     "grade_id": "cell-44f33e587542974d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the *Monte Carlo* policy gradient algorithm. Remember from lab 1 that this means that we will estimate returns for states by sample episodes. Compared to DQN, this means that we do *not* perform an update step at every environment step, but only at the end of each episode. This means that we should generate an episode of data, compute the REINFORCE loss (which requires computing the returns) and then perform a gradient step.\n",
    "\n",
    "To help you, we already implemented a few functions that you can (but do not have to) use.\n",
    "\n",
    "* You can use `torch.multinomial` to sample from a categorical distribution.\n",
    "* The REINFORCE loss is defined as $- \\sum_t \\log \\pi_\\theta(a_t|s_t) G_t$, which means that you should compute the (discounted) return $G_t$ for all $t$. Make sure that you do this in **linear time**, otherwise your algorithm will be very slow! Note the - (minus) since you want to maximize return while you want to minimize the loss.\n",
    "* Importantly, you should **normalize the returns** (not the rewards!, e.g. subtract mean and divide by standard deviation within the episode) before computing the loss, or your estimator will have very high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3b2c75181678fed25fcc7c8b39bb7de3",
     "grade": true,
     "grade_id": "cell-3f6e32c4931392bf",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_action(model, state):\n",
    "    # Samples an action according to the probability distribution induced by the model\n",
    "    # Also returns the log_probability\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return action, log_p[action]\n",
    "\n",
    "def run_episode(env, model):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return episode\n",
    "\n",
    "def compute_reinforce_loss(episode, discount_factor):\n",
    "    # Compute the reinforce loss\n",
    "    # Make sure that your function runs in LINEAR TIME\n",
    "    # Don't forget to normalize your RETURNS (not rewards)\n",
    "    # Note that the rewards/returns should be maximized \n",
    "    # while the loss should be minimized so you need a - somewhere\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return loss\n",
    "\n",
    "def run_episodes_policy_gradient(model, env, num_episodes, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "    \n",
    "    episode_durations = []\n",
    "    for i in range(num_episodes):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "                           \n",
    "        if i % 10 == 0:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                  .format(i, len(episode), '\\033[92m' if len(episode) >= 195 else '\\033[99m'))\n",
    "        episode_durations.append(len(episode))\n",
    "        \n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play around with the parameters!\n",
    "num_episodes = 200\n",
    "discount_factor = 0.99\n",
    "learn_rate = 0.01\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "model = PolicyNetwork(num_hidden)\n",
    "\n",
    "episode_durations_policy_gradient = run_episodes_policy_gradient(\n",
    "    model, env, num_episodes, discount_factor, learn_rate)\n",
    "\n",
    "plt.plot(smooth(episode_durations_policy_gradient, 10))\n",
    "plt.title('Episode durations per episode')\n",
    "plt.legend(['Policy gradient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "454f1fb392b88af636d085896efb2aad",
     "grade": false,
     "grade_id": "cell-ad1138b69e6728a0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 4. Deep Reinforcement Learning (5 bonus points)\n",
    "Note that so far we used the state variables as input. However, the true power of Deep Learning is that we can directly learn from raw inputs, e.g. we can learn to balance the cart pole *by just looking at the screen*. This probably means that you need a deep(er) (convolutional) network, as well as tweaking some parameters, running for more iterations (perhaps on GPU) and do other tricks to stabilize learning. Can you get this to work? This will earn you bonus points!\n",
    "\n",
    "Hints:\n",
    "* You may want to use [Google Colab](https://colab.research.google.com/) such that you can benefit from GPU acceleration.\n",
    "* Even if you don't use Colab, save the weights of your final model and load it in the code here (see example below). Hand in the model file with the .ipynb in a .zip. We likely won't be able to run your training code during grading!\n",
    "* Preprocessing is already done for you, and the observation is the difference between two consequtive frames such that the model can 'see' (angular) speed from a single image. Now do you see why we (sometimes) use the word observation (and not state)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f660e1484fe2bf60d66467326eacb1ba",
     "grade": false,
     "grade_id": "cell-9c9dfa80827c5680",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "class CartPoleRawEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._env = gym.make('CartPole-v0', *args, **kwargs)  #.unwrapped\n",
    "        self.action_space = self._env.action_space\n",
    "        screen_height, screen_width = 40, 80  # TODO\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=255, \n",
    "            shape=(screen_height, screen_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        return self._env.seed(seed)\n",
    "    \n",
    "    def reset(self):\n",
    "        s = self._env.reset()\n",
    "        self.prev_screen = self.screen = self.get_screen()\n",
    "        return self._get_observation()\n",
    "    \n",
    "    def step(self, action):\n",
    "        s, r, done, info = self._env.step(action)\n",
    "        self.prev_screen = self.screen\n",
    "        self.screen = self.get_screen()\n",
    "        return self._get_observation(), r, done, info\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        return self.screen - self.prev_screen\n",
    "    \n",
    "    def _get_cart_location(self, screen_width):\n",
    "        _env = self._env.unwrapped\n",
    "        world_width = _env.x_threshold * 2\n",
    "        scale = screen_width / world_width\n",
    "        return int(_env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "    def get_screen(self):\n",
    "        screen = self._env.unwrapped.render(mode='rgb_array').transpose(\n",
    "            (2, 0, 1))  # transpose into torch order (CHW)\n",
    "        # Strip off the top and bottom of the screen\n",
    "        _, screen_height, screen_width = screen.shape\n",
    "        screen = screen[:, screen_height * 4 // 10:screen_height * 8 // 10]\n",
    "        view_width = screen_height * 8 // 10\n",
    "        cart_location = self._get_cart_location(screen_width)\n",
    "        if cart_location < view_width // 2:\n",
    "            slice_range = slice(view_width)\n",
    "        elif cart_location > (screen_width - view_width // 2):\n",
    "            slice_range = slice(-view_width, None)\n",
    "        else:\n",
    "            slice_range = slice(cart_location - view_width // 2,\n",
    "                                cart_location + view_width // 2)\n",
    "        # Strip off the edges, so that we have a square image centered on a cart\n",
    "        screen = screen[:, :, slice_range]\n",
    "        # Convert to float, rescare, convert to torch tensor\n",
    "        # (this doesn't require a copy)\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        # Resize, and add a batch dimension (BCHW)\n",
    "        #return screen.unsqueeze(0).to(device)\n",
    "        return resize(screen).unsqueeze(0)\n",
    "    \n",
    "    def close(self):\n",
    "        return self._env.close()\n",
    "\n",
    "raw_env = CartPoleRawEnv()\n",
    "s = raw_env.reset()\n",
    "\n",
    "# \n",
    "s, r, done, _ = raw_env.step(env.action_space.sample())\n",
    "\n",
    "raw_env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(raw_env.get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n",
    "\n",
    "# Observations are (-1, 1) while we need to plot (0, 1) so show (rgb + 1) / 2\n",
    "plt.figure()\n",
    "plt.imshow((s.cpu().squeeze(0).permute(1, 2, 0).numpy() + 1) / 2,\n",
    "           interpolation='none')\n",
    "plt.title('Example observation')\n",
    "plt.show()\n",
    "raw_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe you should make it a bit deeper?\n",
    "class DeepPolicy(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(40 * 80 * 3, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten\n",
    "        return F.log_softmax(self.l1(x.view(x.size(0), -1)), -1)\n",
    "    \n",
    "policy = DeepPolicy()\n",
    "filename = 'weights.pt'\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    print(f\"Loading weights from {filename}\")\n",
    "    weights = torch.load(filename, map_location='cpu')\n",
    "    \n",
    "    policy.load_state_dict(weights['policy'])\n",
    "    \n",
    "else:\n",
    "    # Train\n",
    "    \n",
    "    ### TODO some training here, maybe? Or run this on a different machine?\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    print(f\"Saving weights to {filename}\")\n",
    "    torch.save({\n",
    "        # You can add more here if you need, e.g. critic\n",
    "        'policy': policy.state_dict()  # Always save weights rather than objects\n",
    "    },\n",
    "    filename)\n",
    "    \n",
    "def bonus_get_action(x):\n",
    "    return policy(x).exp().multinomial(1)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4502e425cdd9d5db2ec0e9e8e972fa0b",
     "grade": true,
     "grade_id": "cell-0d7bd58a23fdfabb",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "episode_durations = []\n",
    "for i in range(20):  # Not too many since it may take forever to render\n",
    "    test_env = CartPoleRawEnv()\n",
    "    test_env.seed(seed + i)\n",
    "    state = test_env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        steps += 1\n",
    "        with torch.no_grad():\n",
    "            action = bonus_get_action(state).item()\n",
    "        state, reward, done, _ = test_env.step(action)\n",
    "    episode_durations.append(steps)\n",
    "    test_env.close()\n",
    "    \n",
    "plt.plot(episode_durations)\n",
    "plt.title('Episode durations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
